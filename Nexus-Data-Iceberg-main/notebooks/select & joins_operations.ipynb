{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44ef164-c611-4e47-9032-022ef72d3148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/03 09:27:53 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"records\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5abcf7-1a89-4261-bd2b-ef6231d217ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|      nyc|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get list of databases\n",
    "databases = spark.sql(\"SHOW DATABASES\")\n",
    "databases.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a9a726-bdcd-4c89-bae5-ee8a81df43b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|      nyc|           taxis_100|      false|\n",
      "|      nyc|     taxis_100M_time|      false|\n",
      "|      nyc|taxis_1000_50COLUMNS|      false|\n",
      "|      nyc|            taxis_1B|      false|\n",
      "|      nyc|taxis_100_50COLUM...|      false|\n",
      "|      nyc|taxis_100000_50CO...|      false|\n",
      "|      nyc|            taxis_1L|      false|\n",
      "|      nyc|          taxis_1000|      false|\n",
      "|      nyc|            taxis_10|      false|\n",
      "|      nyc|   taxis_1L_5COLUMNS|      false|\n",
      "|      nyc|         taxis_10000|      false|\n",
      "|      nyc|            taxis_1M|      false|\n",
      "|      nyc|          taxis_1L_5|      false|\n",
      "|      nyc|          taxis_10_M|      false|\n",
      "|      nyc|taxis_1000_50COLU...|      false|\n",
      "|      nyc|  taxis_10_50COLUMNS|      false|\n",
      "|      nyc|           taxis_10K|      false|\n",
      "|      nyc|            taxis_1K|      false|\n",
      "|      nyc|           taxis_10L|      false|\n",
      "|      nyc|        taxis_5_100M|      false|\n",
      "+---------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get list of tables in the 'nyc' database\n",
    "tables = spark.sql(\"SHOW TABLES IN nyc\")\n",
    "tables.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200042a2-42d7-49c9-a005-1a495a30ca1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e0948e-c25d-49d2-98b0-88d8c4feeb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# # Start the timer\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Execute the SQL query\n",
    "# df = spark.sql(\"SELECT COUNT(*) FROM nyc.taxis_1000_50_product\")\n",
    "\n",
    "# # Stop the timer\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Show the result\n",
    "# df.show()\n",
    "\n",
    "# # Print the time taken for the query\n",
    "# print(f\"Time taken for the query: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d275327d-5e0c-4b4f-ac87-7223cb68a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming you have the result of a query stored in a Spark DataFrame `df`\n",
    "# df = spark.sql(\"SELECT * FROM nyc.taxis_10000_50COLUMNS\")\n",
    "\n",
    "# # Convert the Spark DataFrame to Pandas\n",
    "# df_pandas = df.toPandas()\n",
    "\n",
    "# # Function to get distinct types of values in a column\n",
    "# def get_distinct_types(column):\n",
    "#     return column.apply(type).nunique()\n",
    "\n",
    "# # Create an empty DataFrame to store results\n",
    "# distinct_types_df = pd.DataFrame(columns=['column_name', 'distinct_types'])\n",
    "\n",
    "# # List to hold the rows\n",
    "# rows = []\n",
    "\n",
    "# # Iterate through each column and get the count of distinct types\n",
    "# for column in df_pandas.columns:\n",
    "#     rows.append({\n",
    "#         'column_name': column,\n",
    "#         'distinct_types': get_distinct_types(df_pandas[column])\n",
    "#     })\n",
    "\n",
    "# # Create a new DataFrame using pd.concat\n",
    "# distinct_types_df = pd.concat([distinct_types_df, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# # Show the result\n",
    "# print(distinct_types_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70057ebc-bb3a-436a-b646-4dae73840854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.sql(\"SELECT COUNT(distinct(extra_col_0)) FROM nyc.taxis_10000_50COLUMNS\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "254d2a16-5e7c-4465-b35e-e92ed33a2f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pandas.to_csv('C:\\\\Users\\\\DataEngg\\\\Downloads\\\\Nexus-Data-Iceberg-main\\\\data_10000.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0a36fa-8e7d-40b4-9aba-677ea93ea21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the Spark DataFrame to Pandas\n",
    "# df_pandas = df.toPandas()\n",
    "\n",
    "# # Save the Pandas DataFrame to a CSV file\n",
    "# df_pandas.to_csv('C:\\\\Users\\\\DataEngg\\\\Downloads\\\\Nexus-Data-Iceberg-main\\\\data_10000.csv', index=False)  # Update the path as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466ea0db-23de-4941-93e8-9d5e9dbae683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.sql(\"SELECT * FROM nyc.taxis_1000_50_product\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e002e6-e382-4205-ad70-43d1b6f79c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.option(\"header\", \"true\").csv('file:///C:/Users/DataEngg/Downloads/Nexus-Data-Iceberg-main/data_10000.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39b0da2-b69e-4e96-a6a0-c5c4784b8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the path to your S3 bucket (make sure the bucket exists)\n",
    "# s3_path = \"s3://prateek-iceberg-tables/iceberg_warehouse/data_10000.csv\"\n",
    "\n",
    "# # Save the DataFrame to S3 in CSV format\n",
    "# df.write.csv(s3_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a494aed-795f-414d-a2a3-4be5c52da1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----------+\n",
      "|date_format(extra_col_3, MM)|sum_col_1  |\n",
      "+----------------------------+-----------+\n",
      "|01                          |42464838147|\n",
      "|02                          |38480956991|\n",
      "|03                          |42470434072|\n",
      "|04                          |41071229725|\n",
      "|05                          |42484840243|\n",
      "|06                          |41062517711|\n",
      "|07                          |42463345310|\n",
      "|08                          |42464213526|\n",
      "|09                          |41070790408|\n",
      "|10                          |42443178586|\n",
      "|11                          |41084725354|\n",
      "|12                          |42485051080|\n",
      "+----------------------------+-----------+\n",
      "\n",
      "Time taken for the query: 1.3060219287872314 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the complex SQL query for 'nyc.taxis_10000_50COLUMNS'\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "DATE_FORMAT(extra_col_3, 'MM'), SUM(extra_col_1) AS sum_col_1  \n",
    "FROM demo.nyc.taxis_100M_50\n",
    "GROUP BY DATE_FORMAT(extra_col_3, 'MM')\n",
    "ORDER BY DATE_FORMAT(extra_col_3, 'MM')\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "df = spark.sql(query)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Show the result\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Print the time taken for the query\n",
    "print(f\"Time taken for the query: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20015ed5-f006-44fe-bd93-23262d112cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f27dac3a-7a5a-4c42-a97d-2972fb21b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sample aggregated select query to get count in \n",
    "\n",
    "# import time\n",
    "\n",
    "# # Start the timer\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Define the complex SQL query for 'nyc.taxis_10000_50COLUMNS'\n",
    "# query = \"\"\"\n",
    "# SELECT\n",
    "#     extra_col_0,  -- Example: Grouping by 'extra_col_0'\n",
    "#     COUNT(*) AS total_records,  -- Count the number of records in each group\n",
    "#     SUM(extra_col_1) AS sum_col_1,  -- Sum of values in 'extra_col_1'\n",
    "#     MAX(extra_col_3) AS max_col_3,  -- Maximum value in 'extra_col_3'\n",
    "#     MIN(extra_col_4) AS min_col_4  -- Minimum value in 'extra_col_4'\n",
    "# FROM\n",
    "#     nyc.taxis_1000_50COLUMNS\n",
    "# GROUP BY\n",
    "#     extra_col_0  -- Grouping by 'extra_col_0'\n",
    "# ORDER BY\n",
    "#     total_records DESC  -- Ordering the result by the total number of records in descending order\n",
    "# LIMIT 100;  -- Limiting the result to the top 100 rows\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute the SQL query\n",
    "# df = spark.sql(query)\n",
    "\n",
    "# # Stop the timer\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Show the result\n",
    "# df.show(truncate=False)\n",
    "\n",
    "# # Print the time taken for the query\n",
    "# print(f\"Time taken for the query: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3eb28d99-cc78-45f6-961c-fc9cb172321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:======================================================>(66 + 1) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------+----------+----------+\n",
      "|extra_col_0|total_records|sum_col_1|max_col_3 |min_col_4 |\n",
      "+-----------+-------------+---------+----------+----------+\n",
      "|RCIJEGKQQO |2            |3444     |2020-03-29|NXWCIYAFLF|\n",
      "|SMUDUCNHCT |2            |16336    |2022-10-11|CQMJGSKEZZ|\n",
      "|EUIOKRIGYF |2            |9926     |2022-03-07|BRMOUOELYE|\n",
      "|RDWYAFOQUW |2            |12513    |2021-12-31|GZZRGUFYVI|\n",
      "|UGAGJBJLIB |2            |6489     |2019-09-26|AIBYEXPLRZ|\n",
      "|KGNDQROJZX |2            |12822    |2019-06-04|CAHSZYJWYP|\n",
      "|GOOOVIDFGP |2            |14710    |2021-02-26|GYOPMFYNLV|\n",
      "|RETMZYNKUO |2            |10944    |2020-11-17|EFPIIMLRCR|\n",
      "|AMDDDTEZPF |2            |9843     |2020-03-18|AMKDMLVQVV|\n",
      "|VHXDXXSWNE |2            |5331     |2020-07-17|FQTKMUQOAC|\n",
      "|HTISVAKSHI |2            |1261     |2020-01-26|FMOYZOUVOY|\n",
      "|EVDENFQWBQ |2            |4469     |2019-12-11|QYSBWCVDAX|\n",
      "|PTBXGFHCBV |2            |10863    |2024-04-03|PLJVRZFGYS|\n",
      "|ONONAPKYZK |2            |16500    |2021-08-18|KPMAKSRUGF|\n",
      "|YRTDFLPYJG |2            |11245    |2022-11-25|DCBHJOKFBB|\n",
      "|CDPPMMHQRK |2            |9798     |2020-01-03|CDYVFFYGTB|\n",
      "|FXDTOMAIBI |2            |6541     |2017-10-07|TTQUZGYLVD|\n",
      "|HBHVYJGRFY |2            |7971     |2022-12-06|CYHWNQRUSH|\n",
      "|PBIASHQEUW |2            |17516    |2021-09-27|KEVVVWQKZW|\n",
      "|OZMJDVSWWD |2            |7647     |2024-08-16|URZZSGLEHU|\n",
      "+-----------+-------------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken for the query: 603.3699321746826 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the complex SQL query for 'nyc.taxis_10M_50COLUMNS'\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    extra_col_0,\n",
    "    COUNT(*) AS total_records,\n",
    "    SUM(extra_col_1) AS sum_col_1,\n",
    "    MAX(extra_col_3) AS max_col_3,\n",
    "    MIN(extra_col_4) AS min_col_4\n",
    "FROM\n",
    "    nyc.taxis_100M_50\n",
    "GROUP BY\n",
    "    extra_col_0\n",
    "ORDER BY\n",
    "    total_records DESC\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "df = spark.sql(query)\n",
    "\n",
    "# Force computation of the result (avoid serving from cache)\n",
    "df.count()\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Show the result\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Print the time taken for the query\n",
    "print(f\"Time taken for the query: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf31939a-76ee-40ce-af20-5b060d5e8f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 151:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+---------------+-------------+\n",
      "|extra_col_0|extra_col_1|extra_col_1_b|extra_col_2    |extra_col_2_b|\n",
      "+-----------+-----------+-------------+---------------+-------------+\n",
      "|AAPXCANGJC |2607       |NULL         |KWXFMTFSUFGQDRC|NULL         |\n",
      "|ACLYVVNHAM |3574       |NULL         |KOUXEDRNYIFNLMA|NULL         |\n",
      "|ACMEHLUEHE |8526       |NULL         |FVBLYYCVPEVZJOH|NULL         |\n",
      "|ADUUGUCIKL |6903       |NULL         |SSKMTUWVWWLQNDY|NULL         |\n",
      "|AEOUKLHQTM |5679       |NULL         |WVBQSPSXCQVGURS|NULL         |\n",
      "|AERPSIJJJK |208        |NULL         |WWAUPACXKIYSFUR|NULL         |\n",
      "|AFEBQHPGLS |9307       |NULL         |UWPRLTUVPYISDRM|NULL         |\n",
      "|AGBIVJGVEX |5032       |NULL         |BWAFAKSIGPFOCLC|NULL         |\n",
      "|AGRMKBQETQ |8163       |NULL         |ANLYSOGFEMXXPPK|NULL         |\n",
      "|AGSYDJYBSB |136        |NULL         |QRJABQIQGBZKKYI|NULL         |\n",
      "|AHNHHPDVSU |3412       |NULL         |ETYPJLDYZVEUETQ|NULL         |\n",
      "|AINJPMQFIJ |1711       |NULL         |IIDXRSSRUJKLVGY|NULL         |\n",
      "|AIPVQRJQOR |132        |NULL         |LKCDMSZZKOMTLGJ|NULL         |\n",
      "|AMHXFWXNQC |7945       |NULL         |SCGHFQNTJWYHNOB|NULL         |\n",
      "|AOFMLVGAGD |786        |NULL         |LEMILKNQXVLXZQD|NULL         |\n",
      "|AOIPVXXXND |4686       |NULL         |QVIKWSBATJIOXFY|NULL         |\n",
      "|AOJAKXMTBU |4011       |NULL         |OCCTDNPMZLLKKWL|NULL         |\n",
      "|APKJBAGNXP |5852       |NULL         |ZJYRUAKTXAWUKMX|NULL         |\n",
      "|AQIUISKSHJ |3284       |NULL         |LOBOONGHULZMELS|NULL         |\n",
      "|AQWWZKAIBJ |1950       |NULL         |UHYUSWEXLPPIGHN|NULL         |\n",
      "+-----------+-----------+-------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total time taken for the query execution (including join operation): 73.63867974281311 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer (this will capture the total time for the query execution, including the join operation)\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the SQL query for performing the JOIN operation on 'extra_col_0'\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    a.extra_col_0,  -- extra_col_0 from the first table (nyc.taxis_1000_50COLUMNS)\n",
    "    a.extra_col_1,  -- Example of another column from the first table\n",
    "    b.extra_col_1 AS extra_col_1_b,  -- Example of another column from the second table\n",
    "    a.extra_col_2,  -- Example column from the first table\n",
    "    b.extra_col_2 AS extra_col_2_b   -- Example column from the second table\n",
    "FROM\n",
    "    nyc.taxis_100M_50 a\n",
    "LEFT JOIN\n",
    "    nyc.taxis_10M_50COLUMNS b\n",
    "ON\n",
    "    a.extra_col_0 = b.extra_col_0  -- Join condition on extra_col_0\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query and trigger the action (this will start the query execution)\n",
    "df = spark.sql(query)\n",
    "\n",
    "# Show the result (this forces Spark to execute the query and perform the join)\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Stop the timer after the query execution is done\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total time taken for the query execution, including the join\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Print the total time taken for the query execution (including join)\n",
    "print(f\"Total time taken for the query execution (including join operation): {total_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2f878-06ed-47a1-b928-f8f807ed1e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
