{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee35e052-86b4-42f5-83cf-9efbddb22c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (2.2.1)\n",
      "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.9/site-packages (3.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd5394c-0ce8-4b3d-91de-f9839ff09bd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m----> 2\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/session.py:493\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39m_instantiatedSession\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 493\u001b[0m     sparkConf \u001b[38;5;241m=\u001b[39m \u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    495\u001b[0m         sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/conf.py:132\u001b[0m, in \u001b[0;36mSparkConf.__init__\u001b[0;34m(self, loadDefaults, _jvm, _jconf)\u001b[0m\n\u001b[1;32m    128\u001b[0m _jvm \u001b[38;5;241m=\u001b[39m _jvm \u001b[38;5;129;01mor\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_jvm\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# JVM is created, so create self._jconf directly through JVM\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf \u001b[38;5;241m=\u001b[39m \u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparkConf\u001b[49m(loadDefaults)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# JVM is not created, so store data in self._conf first\u001b[39;00m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1712\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m UserHelpAutoCompletion\u001b[38;5;241m.\u001b[39mKEY:\n\u001b[1;32m   1710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[0;32m-> 1712\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFLECTION_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEND_COMMAND_PART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaPackage(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, jvm_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"records\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0eb2fbb-97ed-4810-9303-bde3d14b628c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP TABLE IF EXISTS demo.nyc.taxis_1000_50_product\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    " spark.sql(\"DROP TABLE IF EXISTS demo.nyc.taxis_1000_50_product\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bda4a8b-f73f-4b25-bc17-f95cb555aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "iceberg_table_dir = \"../warehouse/nyc/taxis_1000_50_product\"\n",
    "metadata_dir = f\"{iceberg_table_dir}/metadata\"\n",
    "data_dir = f\"{iceberg_table_dir}/data\"\n",
    "input_data_dir = f\"../input_data\"\n",
    "analysis_info = []\n",
    "records_before_op = 0\n",
    "\n",
    "def append_to_file(file_path, msg):\n",
    "    open_mode = \"a\"\n",
    "    if not os.path.exists(file_path):\n",
    "        open_mode = \"w\"\n",
    "\n",
    "    # Open the CSV file in write mode\n",
    "    with open(file_path, open_mode) as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        if open_mode==\"w\":\n",
    "            #writing header of the columns\n",
    "            writer.writerows([list(msg.keys())])    \n",
    "\n",
    "        row_values = [list(msg.values())]\n",
    "        # Write the data to the CSV file\n",
    "        writer.writerows(row_values)\n",
    "\n",
    "def get_size():\n",
    "    # List the metadata files\n",
    "    manifest_pattern = re.compile(r\".*-m\\d+\\.avro$\")\n",
    "    metadata_files = os.listdir(metadata_dir)\n",
    "    \n",
    "    # Initialize variables to store the sizes of different types of metadata files\n",
    "    snap_avro_size = 0\n",
    "    metadata_json_size = 0\n",
    "    m_avro_size = 0\n",
    "\n",
    "    data_dir_size = 0\n",
    "    # get data dir size\n",
    "    data_dir_files = os.listdir(data_dir)\n",
    "    # print(data_dir_files)\n",
    "    for filename in data_dir_files:\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        data_dir_size += os.path.getsize(file_path) / 1024  # Convert size to KB\n",
    "    \n",
    "    # Iterate through the metadata files and calculate their sizes\n",
    "    for file in metadata_files:\n",
    "        file_path = os.path.join(metadata_dir, file)\n",
    "        file_size_kb = os.path.getsize(file_path) / 1024  # Convert size to KB\n",
    "        \n",
    "        if file.startswith(\"snap-\") and file.endswith(\".avro\"):\n",
    "            snap_avro_size += file_size_kb\n",
    "        elif file.endswith(\".metadata.json\"):\n",
    "            metadata_json_size += file_size_kb\n",
    "        elif manifest_pattern.match(file):\n",
    "            m_avro_size += file_size_kb\n",
    "    \n",
    "    # Print the time taken and the sizes of the metadata files\n",
    "    # print(f\"Time taken to read Parquet files: {time_taken:.2f} seconds\")\n",
    "    # print(f\"Size of snap-*.avro files: {snap_avro_size:.2f} KB\")\n",
    "    # print(f\"Size of *.metadata.json files: {metadata_json_size:.2f} KB\")\n",
    "    # print(f\"Size of *m{0-9}{1,}.avro files: {m_avro_size:.2f} KB\")\n",
    "\n",
    "    return {\"data_dir_size\": data_dir_size,\"metadata_size\": metadata_json_size,\"snapshot_size\": snap_avro_size,\"manifest_size\": m_avro_size}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc52770e-bf50-4028-9d58-916f919225c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/28 12:18:19 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "|extra_col_0|extra_col_1|extra_col_2|extra_col_3|extra_col_4|extra_col_5|extra_col_6|extra_col_7|extra_col_8|extra_col_9|extra_col_10|extra_col_11|extra_col_12|extra_col_13|extra_col_14|extra_col_15|extra_col_16|extra_col_17|extra_col_18|extra_col_19|extra_col_20|extra_col_21|extra_col_22|extra_col_23|extra_col_24|extra_col_25|extra_col_26|extra_col_27|extra_col_28|extra_col_29|extra_col_30|extra_col_31|extra_col_32|extra_col_33|extra_col_34|extra_col_35|extra_col_36|extra_col_37|extra_col_38|extra_col_39|extra_col_40|extra_col_41|extra_col_42|extra_col_43|extra_col_44|extra_col_45|extra_col_46|extra_col_47|extra_col_48|extra_col_49|\n",
      "+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "| ZELOYYZESY|       7324|         TW| 2024-12-01| XLEDCBCWNC|       9767|        CAR| 2020-09-01| BXDVVCOJVP|       8704|         CAR|  2021-03-01|  JILWWEGGNR|         437|          CV|  2023-09-01|  HXSWNWLRTT|         135|          TW|  2022-01-01|  PSKLAZBIQB|        4699|         CAR|  2023-12-01|  KIFTZDBTSL|        1755|          TW|  2022-03-01|  PCBWMBQQQY|        6963|          CV|  2021-10-01|  BQFLMWCSCQ|        5406|          CV|  2022-06-01|  JNWDHQQQCE|        9445|          TW|  2023-05-01|  PAULIXTJCU|        8090|         CAR|  2021-03-01|  EEUBWHRWAP|        1858|          TW|  2021-03-01|  TMAORRWZCX|        9691|\n",
      "| UDFYBLMVAY|       7141|         CV| 2022-06-01| QUJYOJMBNF|       6125|        CAR| 2024-01-01| PDHCZZHOCP|       1155|          CV|  2020-02-01|  ZRZLBLEIXV|        1068|         CAR|  2022-12-01|  ARJIDCLPVZ|        5639|          CV|  2022-09-01|  DKAYFJLDSH|        2146|          CV|  2023-02-01|  COSQZWUZYW|        2218|         CAR|  2024-08-01|  HBLVGCTZDM|        5534|          TW|  2021-05-01|  SKGEMEFMBN|        4820|          TW|  2022-04-01|  LFHQGVQHRN|        4932|         CAR|  2021-12-01|  MGOQBFLUAH|        8322|         CAR|  2024-03-01|  BHEKDEJIND|        7315|         CAR|  2020-04-01|  WGVHQMKMGX|        6593|\n",
      "| KMNQFBGPTK|       1442|        CAR| 2022-07-01| TOGFOMOYPA|       3903|         CV| 2020-03-01| LRTFEVUHRA|       2871|         CAR|  2020-12-01|  JNOWCLHATV|        7011|         CAR|  2024-07-01|  GMQXWPNANT|        6463|         CAR|  2021-08-01|  SGUNJBOVEK|        8293|         CAR|  2023-08-01|  JRFHYCQLQL|        8779|          TW|  2022-06-01|  MMYPZHLSFN|        8777|          TW|  2024-11-01|  XVQMTNSBDP|        7735|          TW|  2022-06-01|  WXPRAIWSZQ|        8782|          TW|  2024-06-01|  KUFMVDQTPK|        3153|          TW|  2021-09-01|  HHUZPERWHI|        1745|          CV|  2022-11-01|  ANGSYWZFVS|        5213|\n",
      "| ZARVKXXVRE|       8814|        CAR| 2022-06-01| ZOHCGPZAJN|       4568|         TW| 2021-06-01| VKLWWJJYOI|       7102|          TW|  2020-10-01|  ZPLXLEJFWS|        8366|          TW|  2021-05-01|  TWSCGFMHQF|        6079|          TW|  2020-07-01|  KHNECHZWJZ|        6538|         CAR|  2020-08-01|  TXPDJKNUCV|        1146|          CV|  2020-11-01|  XEXSOFFSMB|        8414|          CV|  2020-11-01|  CKYAKJEFNC|        1906|         CAR|  2021-06-01|  MDAFFZXNZM|        9750|          CV|  2022-04-01|  LKSMSCREUG|        3010|          CV|  2024-07-01|  GAWOFKAYPV|        3264|          CV|  2023-04-01|  BWRJZOATAU|         711|\n",
      "| UOUKDDBZDT|       5222|        CAR| 2022-08-01| ZOIXJCXCOH|       5419|        CAR| 2022-11-01| UZLCYRUBZC|       2917|          TW|  2024-04-01|  UPZVDNFRGM|         778|          CV|  2023-07-01|  DIEWSHTOJB|        6937|          TW|  2020-04-01|  PTQGGDQKCO|        2591|          CV|  2021-12-01|  FCSPQXQHSF|        3541|         CAR|  2021-11-01|  ZXCERUXJSX|        2046|         CAR|  2022-12-01|  UHGASFWKGG|        3061|          CV|  2022-11-01|  MFVFVZESJU|        1453|          TW|  2021-05-01|  MXSFQHJXFE|        1891|         CAR|  2025-01-01|  BOQZGKHRHW|        6764|          CV|  2023-09-01|  AWLEBYKEEQ|         590|\n",
      "+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, DateType\n",
    ")\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Generate Taxis Data\").getOrCreate()\n",
    "\n",
    "def generate_random_month_date():\n",
    "    \"\"\"Generate a random date with the first day of a month.\"\"\"\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    end_date = datetime.today()\n",
    "    delta = end_date - start_date\n",
    "    random_days = random.randint(0, delta.days)\n",
    "    random_date = start_date + timedelta(days=random_days)\n",
    "    \n",
    "    return random_date.replace(day=1)  # Ensuring DATE format\n",
    "\n",
    "# Define schema ensuring extra_col_3 is DateType\n",
    "schema = StructType([\n",
    "    StructField(f\"extra_col_{i}\", StringType(), True) if i % 4 == 0 else  \n",
    "    StructField(f\"extra_col_{i}\", IntegerType(), True) if i % 4 == 1 else  \n",
    "    StructField(f\"extra_col_{i}\", StringType(), True) if i % 4 == 2 else  \n",
    "    StructField(f\"extra_col_{i}\", DateType(), True)  # Ensure DATE type for extra_col_3\n",
    "    for i in range(50)\n",
    "])\n",
    "\n",
    "def generate_records(n):\n",
    "    \"\"\"Generate records based on schema.\"\"\"\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        row = [\n",
    "            ''.join(random.choice(string.ascii_uppercase) for _ in range(10)) if i % 4 == 0 else\n",
    "            random.randint(1, 10000) if i % 4 == 1 else\n",
    "            random.choice([\"CAR\", \"TW\", \"CV\"]) if i % 4 == 2 else\n",
    "            generate_random_month_date()  # Ensure DATE type\n",
    "            for i in range(50)\n",
    "        ]\n",
    "        data.append(row)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate Data\n",
    "records = generate_records(1000)  # Adjust number of records\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(records, schema)\n",
    "\n",
    "# Ensure extra_col_3 is stored as DateType\n",
    "df = df.withColumn(\"extra_col_3\", F.to_date(F.col(\"extra_col_3\")))\n",
    "\n",
    "# Show sample records\n",
    "df.show(5)\n",
    "\n",
    "# Save to Iceberg Table\n",
    "df.writeTo(\"demo.nyc.taxis_1000_50_product\").create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72f44de1-3b71-4e66-9ebc-6dcdc99ccc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "|extra_col_0|extra_col_1|extra_col_2|extra_col_3|extra_col_4|extra_col_5|extra_col_6|extra_col_7|extra_col_8|extra_col_9|extra_col_10|extra_col_11|extra_col_12|extra_col_13|extra_col_14|extra_col_15|extra_col_16|extra_col_17|extra_col_18|extra_col_19|extra_col_20|extra_col_21|extra_col_22|extra_col_23|extra_col_24|extra_col_25|extra_col_26|extra_col_27|extra_col_28|extra_col_29|extra_col_30|extra_col_31|extra_col_32|extra_col_33|extra_col_34|extra_col_35|extra_col_36|extra_col_37|extra_col_38|extra_col_39|extra_col_40|extra_col_41|extra_col_42|extra_col_43|extra_col_44|extra_col_45|extra_col_46|extra_col_47|extra_col_48|extra_col_49|\n",
      "+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "| ZELOYYZESY|       7324|         TW| 2024-12-01| XLEDCBCWNC|       9767|        CAR| 2020-09-01| BXDVVCOJVP|       8704|         CAR|  2021-03-01|  JILWWEGGNR|         437|          CV|  2023-09-01|  HXSWNWLRTT|         135|          TW|  2022-01-01|  PSKLAZBIQB|        4699|         CAR|  2023-12-01|  KIFTZDBTSL|        1755|          TW|  2022-03-01|  PCBWMBQQQY|        6963|          CV|  2021-10-01|  BQFLMWCSCQ|        5406|          CV|  2022-06-01|  JNWDHQQQCE|        9445|          TW|  2023-05-01|  PAULIXTJCU|        8090|         CAR|  2021-03-01|  EEUBWHRWAP|        1858|          TW|  2021-03-01|  TMAORRWZCX|        9691|\n",
      "| UDFYBLMVAY|       7141|         CV| 2022-06-01| QUJYOJMBNF|       6125|        CAR| 2024-01-01| PDHCZZHOCP|       1155|          CV|  2020-02-01|  ZRZLBLEIXV|        1068|         CAR|  2022-12-01|  ARJIDCLPVZ|        5639|          CV|  2022-09-01|  DKAYFJLDSH|        2146|          CV|  2023-02-01|  COSQZWUZYW|        2218|         CAR|  2024-08-01|  HBLVGCTZDM|        5534|          TW|  2021-05-01|  SKGEMEFMBN|        4820|          TW|  2022-04-01|  LFHQGVQHRN|        4932|         CAR|  2021-12-01|  MGOQBFLUAH|        8322|         CAR|  2024-03-01|  BHEKDEJIND|        7315|         CAR|  2020-04-01|  WGVHQMKMGX|        6593|\n",
      "| KMNQFBGPTK|       1442|        CAR| 2022-07-01| TOGFOMOYPA|       3903|         CV| 2020-03-01| LRTFEVUHRA|       2871|         CAR|  2020-12-01|  JNOWCLHATV|        7011|         CAR|  2024-07-01|  GMQXWPNANT|        6463|         CAR|  2021-08-01|  SGUNJBOVEK|        8293|         CAR|  2023-08-01|  JRFHYCQLQL|        8779|          TW|  2022-06-01|  MMYPZHLSFN|        8777|          TW|  2024-11-01|  XVQMTNSBDP|        7735|          TW|  2022-06-01|  WXPRAIWSZQ|        8782|          TW|  2024-06-01|  KUFMVDQTPK|        3153|          TW|  2021-09-01|  HHUZPERWHI|        1745|          CV|  2022-11-01|  ANGSYWZFVS|        5213|\n",
      "| ZARVKXXVRE|       8814|        CAR| 2022-06-01| ZOHCGPZAJN|       4568|         TW| 2021-06-01| VKLWWJJYOI|       7102|          TW|  2020-10-01|  ZPLXLEJFWS|        8366|          TW|  2021-05-01|  TWSCGFMHQF|        6079|          TW|  2020-07-01|  KHNECHZWJZ|        6538|         CAR|  2020-08-01|  TXPDJKNUCV|        1146|          CV|  2020-11-01|  XEXSOFFSMB|        8414|          CV|  2020-11-01|  CKYAKJEFNC|        1906|         CAR|  2021-06-01|  MDAFFZXNZM|        9750|          CV|  2022-04-01|  LKSMSCREUG|        3010|          CV|  2024-07-01|  GAWOFKAYPV|        3264|          CV|  2023-04-01|  BWRJZOATAU|         711|\n",
      "| UOUKDDBZDT|       5222|        CAR| 2022-08-01| ZOIXJCXCOH|       5419|        CAR| 2022-11-01| UZLCYRUBZC|       2917|          TW|  2024-04-01|  UPZVDNFRGM|         778|          CV|  2023-07-01|  DIEWSHTOJB|        6937|          TW|  2020-04-01|  PTQGGDQKCO|        2591|          CV|  2021-12-01|  FCSPQXQHSF|        3541|         CAR|  2021-11-01|  ZXCERUXJSX|        2046|         CAR|  2022-12-01|  UHGASFWKGG|        3061|          CV|  2022-11-01|  MFVFVZESJU|        1453|          TW|  2021-05-01|  MXSFQHJXFE|        1891|         CAR|  2025-01-01|  BOQZGKHRHW|        6764|          CV|  2023-09-01|  AWLEBYKEEQ|         590|\n",
      "| ECVSLAMXPG|       1196|         CV| 2020-06-01| KLNKDCLPVI|       9925|         CV| 2020-08-01| XCMBOONQCD|       8172|          CV|  2021-03-01|  VUIWRQPZQL|        5102|          TW|  2023-08-01|  CPBIWGXFKF|        7120|          CV|  2023-06-01|  NAPXLNJMJB|        5391|         CAR|  2023-04-01|  LACGRKGSCQ|        5371|          CV|  2024-04-01|  YIBQTIACXC|        8927|          TW|  2020-10-01|  QYSAPRIMTH|        1996|          TW|  2024-06-01|  AGKRECSXYM|        4233|         CAR|  2023-01-01|  ROKEYWDYXG|        9108|          TW|  2020-04-01|  ZBRSUTDYIN|        9208|         CAR|  2020-03-01|  OWSUDAMGJA|        7199|\n",
      "| TYNAVRWJML|       9941|        CAR| 2022-03-01| XQQSNCGLSL|       3501|         CV| 2020-12-01| LTBLQBHOAP|        946|         CAR|  2021-01-01|  IVKRNTMYMV|        8880|          CV|  2021-01-01|  REZSFLFWYE|        8984|          TW|  2024-02-01|  PNRRXSMWQQ|        2487|          TW|  2022-08-01|  BUWZCFACCB|         326|         CAR|  2022-02-01|  BLQFAJCBGJ|        3112|         CAR|  2023-09-01|  SZCKQJKCQI|        7300|          CV|  2023-12-01|  GIHVLOYQVL|        5854|          CV|  2024-04-01|  CLYJRFVKJI|        9503|          CV|  2022-11-01|  JTKOTMSHEP|        3686|          TW|  2022-03-01|  HERBARXAYH|         326|\n",
      "| FLXRVUYHYS|        773|         TW| 2021-08-01| VLWDYOOTAU|       8194|        CAR| 2022-03-01| MLFGELNUEZ|       6684|          TW|  2024-03-01|  IKAMAKKEYH|        4980|          TW|  2024-11-01|  VYKXVSDYDC|        7262|          TW|  2022-08-01|  MAGGINOAZY|        8209|         CAR|  2024-12-01|  ZQYQKQRDJS|        3435|          TW|  2020-04-01|  ZYMFEWPJZQ|        9158|          CV|  2024-11-01|  WPMIEZJXNY|        4789|          CV|  2024-01-01|  GDHAJTZXVB|        9400|          CV|  2021-03-01|  YLTVGTFSGV|        7472|          CV|  2025-01-01|  PDETCTZQOV|        6235|         CAR|  2024-10-01|  CRBVQFLLOA|        8683|\n",
      "| NROVCEAHNG|       2478|         TW| 2024-07-01| TGBPRZXYNN|       4750|         CV| 2021-09-01| MGJDLPCDFN|       6097|         CAR|  2021-05-01|  HMIQMDQMEF|         359|         CAR|  2023-10-01|  IERZUDPBOL|        3575|         CAR|  2024-12-01|  THWVIRRYUZ|        4578|         CAR|  2021-06-01|  FNYNUCLSCW|        5334|         CAR|  2021-02-01|  QFFAGTKDFP|        8054|         CAR|  2022-05-01|  LDEVKRQDNH|        8580|         CAR|  2022-04-01|  UQPLNIGHWC|        3499|         CAR|  2023-06-01|  IKVZUUAGHH|        2031|          TW|  2021-05-01|  BHBMUTEYMO|        3614|         CAR|  2025-01-01|  RAEJQGMATM|        5082|\n",
      "| PBUDIOAPQF|        380|         TW| 2021-03-01| HMHAGSGHTG|         37|         CV| 2023-11-01| MUAMUUXWFI|        665|         CAR|  2020-05-01|  IHLKLHKQXG|        7317|          CV|  2024-05-01|  DLLUYADHHJ|        6280|         CAR|  2021-05-01|  KDVEYAKWZQ|        4339|         CAR|  2024-03-01|  DOABMGPPEY|        1501|          TW|  2020-12-01|  XGDWKWAFOM|        1406|         CAR|  2022-05-01|  LTCCTGFFPB|        3001|          CV|  2022-06-01|  DPPPCIPLVY|        3638|         CAR|  2024-03-01|  BBNSAWDKWS|        2609|         CAR|  2021-07-01|  BLXIAVZJZC|        4805|          TW|  2022-05-01|  JSMOSMPYLD|         784|\n",
      "| MGGYGZXNWP|       7591|         TW| 2023-06-01| WVSNGLUBUE|       4693|        CAR| 2024-06-01| GNGMNLBPUH|       7245|          TW|  2024-09-01|  VEWIBPPTPI|         485|          TW|  2023-03-01|  YWKYJBYFZK|        4388|         CAR|  2024-11-01|  QVEEXDQWCP|        8357|         CAR|  2022-07-01|  MCMHWSLPNA|        6151|         CAR|  2025-02-01|  TQVKTZEJCD|        2179|         CAR|  2020-09-01|  APTZIFUKHY|        3274|          CV|  2022-11-01|  DGVKLYYEHC|         318|          CV|  2021-06-01|  LHSCAOQTYJ|        7003|          CV|  2024-09-01|  JFFRDCLZWQ|        8475|         CAR|  2021-12-01|  ZMZBNIDFXC|        3116|\n",
      "| YAHUCWJNOX|       7996|        CAR| 2020-02-01| AQAAKTNHCM|       8699|        CAR| 2023-11-01| GIQCEXEYQK|       1911|          CV|  2025-01-01|  FFJSHGSZDL|        8734|          TW|  2020-10-01|  EOEZGVZXKK|        7249|          CV|  2023-12-01|  TRRMIWKXAS|        7131|         CAR|  2024-11-01|  BCKVOMARON|        9437|          TW|  2023-04-01|  IIFVGUQLTN|        1607|          CV|  2024-12-01|  JOWYSFQYHR|        1823|         CAR|  2022-05-01|  SUAVOHXMWI|        4025|         CAR|  2024-05-01|  EGYIYBPHDE|        7326|          TW|  2021-10-01|  LQYXUAZPDI|        3174|          CV|  2022-11-01|  YHRKZIZEDK|        2899|\n",
      "| SWIERYKGTN|       1859|         CV| 2021-11-01| JCHYRXKCNF|       9970|         CV| 2021-10-01| BCUSOFXGMN|       2102|          TW|  2022-03-01|  GJMCDQBKYW|          56|          CV|  2021-03-01|  METGTFZCNI|        1067|          CV|  2021-09-01|  DRDHMKNBWO|        4304|          CV|  2021-02-01|  LEQUNJWMKK|        9749|          TW|  2024-11-01|  KIYOIATMST|        7912|          TW|  2020-04-01|  JVGZHTFIAR|        4893|          CV|  2022-06-01|  NNCMPWVUSC|         564|         CAR|  2022-01-01|  IZPHIREELY|        3976|          CV|  2025-02-01|  UFIZEHSSZQ|        7871|          TW|  2021-02-01|  SMWIAKQMAP|        6342|\n",
      "| UEOLGGOAKB|       9603|        CAR| 2025-01-01| BZTJODJVHD|       7725|         CV| 2020-06-01| JYDIVHUTKV|       5863|          TW|  2022-06-01|  NBFVKOIVXU|        9596|         CAR|  2024-07-01|  KTZTTECBGL|        6239|          CV|  2024-09-01|  GXBKIJESFS|        1755|         CAR|  2021-04-01|  SHTQLAKSGA|        3764|          CV|  2023-03-01|  PPFRVXHCGS|        6512|         CAR|  2023-09-01|  AHMRCUMNHG|         235|         CAR|  2024-05-01|  YDWHXSLKKW|        6045|         CAR|  2020-10-01|  GUICAMYAIK|        7410|          CV|  2022-09-01|  CZMZNZUWFF|        1369|         CAR|  2021-09-01|  BYCHAJWMSR|        2493|\n",
      "| URDANJDHSX|       2310|         CV| 2023-12-01| MHMHKGUMOH|       5695|        CAR| 2024-06-01| QRBYSWLTVP|       9958|         CAR|  2020-02-01|  FBVULSHZEU|        6021|          TW|  2023-06-01|  SMWOIGVXBY|        5166|          TW|  2020-03-01|  MCDDQLGYCM|        9529|         CAR|  2023-06-01|  ELCTBQCESK|        1439|          TW|  2022-05-01|  VXOOUDYQQR|        3692|          TW|  2023-01-01|  FUNPWUWSZY|        9422|          TW|  2025-02-01|  TTMDRVLOJN|        8014|          TW|  2024-01-01|  HRVZHOQOQD|        6893|          CV|  2021-02-01|  YCIVJHPTIT|        6419|         CAR|  2024-03-01|  NHDXCUMECU|        1981|\n",
      "| HZVESIJMSE|       8500|        CAR| 2021-01-01| ODFUVUQGFA|       6435|        CAR| 2023-06-01| NKBVTUOFBF|       4502|          CV|  2020-03-01|  DVZADOJCGC|        3011|          TW|  2025-01-01|  MWFQRCIJRI|        5314|          CV|  2022-05-01|  UIAHTVDUDX|        1394|          CV|  2022-08-01|  ZLJLWWSLDH|        1885|         CAR|  2023-03-01|  JVHIONVXEV|        8446|          TW|  2024-11-01|  LSYFIRJKBL|        1183|          TW|  2023-05-01|  FSWGSNVKEU|        5170|         CAR|  2022-09-01|  LAYDPEGQFP|        9254|          CV|  2024-02-01|  RKJZGISXSZ|        8327|          TW|  2021-07-01|  VZRAHZQWYA|        3135|\n",
      "| LBDEODLRFD|        895|        CAR| 2021-01-01| TRGNYQXWWQ|       4953|         TW| 2024-08-01| EAPYIYEILF|       8018|          TW|  2023-05-01|  DIDAAJYJJE|        2828|         CAR|  2022-09-01|  FTLNNBOZMW|        1818|          CV|  2021-03-01|  XYJTAVHOFK|        9348|          CV|  2023-11-01|  PWHXPGERGV|        3798|          CV|  2022-02-01|  IRNRPHQUMG|        2461|         CAR|  2020-01-01|  HQSYYBMDPV|        7712|         CAR|  2020-12-01|  DKZQKDBTAW|        3989|          TW|  2023-10-01|  SGJNILVKWA|        3522|          CV|  2024-02-01|  BIDXBQYPGF|        4383|          TW|  2021-04-01|  BPZAKSDSWW|        8139|\n",
      "| QDXZNEDNPH|        659|        CAR| 2024-07-01| FLMFNBQGBS|       2163|         CV| 2020-12-01| MFLJMXMQJG|       3162|          TW|  2023-04-01|  YFDFVCOIUO|         127|         CAR|  2024-01-01|  LWQBVYHDBY|        6338|          CV|  2023-05-01|  KXJLVZZQWQ|        2877|          TW|  2021-05-01|  ETXQWGZETU|        4122|         CAR|  2023-10-01|  SKDRGMQCRO|        5301|          TW|  2021-05-01|  VTHESKHVLL|        5301|         CAR|  2020-03-01|  CARKVHDLMF|        1692|          TW|  2020-12-01|  OCNXPMZNFC|        5747|         CAR|  2024-03-01|  DPQIWGMXOH|        5335|          TW|  2021-10-01|  RFATQSOKYI|        3622|\n",
      "| SEKHDOYAFI|        917|         CV| 2024-09-01| MOFZTQGXUG|       5382|        CAR| 2020-10-01| MDBYJZSEGG|        495|          TW|  2021-08-01|  MAFIQOGOQB|          38|          TW|  2023-03-01|  NVAEUDHLZX|        7961|          CV|  2022-11-01|  MDHOHDJLHX|        8659|          TW|  2021-12-01|  PTKBOLEWLI|        1644|          CV|  2023-08-01|  LSSONDLXPN|        5035|          TW|  2021-05-01|  TPNPFISTXJ|        5683|          TW|  2022-03-01|  HURIGXQOQI|        4989|         CAR|  2023-10-01|  SSVBSKTRMU|        3536|          TW|  2020-01-01|  QTXAOQHJWJ|        6218|          CV|  2024-02-01|  ASIUVFHDLX|        6452|\n",
      "| TIGOSGKQNQ|       7728|         TW| 2022-03-01| OOBWYRMPYC|       6098|         TW| 2020-04-01| QXZQCUMWWG|       5292|          CV|  2021-08-01|  AUVPLJRILK|        5259|          TW|  2023-06-01|  VRMJSXZVRC|        1080|          CV|  2022-03-01|  PSXGZHUWRG|        6721|          TW|  2021-10-01|  BCKHGTSYBZ|        8118|          TW|  2021-02-01|  FENESBWCCG|        5110|          CV|  2022-02-01|  SDKEEWYKRU|        1569|         CAR|  2022-01-01|  PHOOSQWZMQ|        1418|          CV|  2020-04-01|  IMFECKDJNJ|        7835|          CV|  2021-06-01|  JVXMZSMPTN|        7344|         CAR|  2025-01-01|  WPSZTQFKIA|        2667|\n",
      "+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.table(\"demo.nyc.taxis_1000_50_product\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8c952b9-cac6-407d-82c9-afcdf1f52a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter input file type (csv or parquet):  parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: records_1000_1_1740744671.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 1000 records in 1.32 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "input_data_dir = \"../input_data\"\n",
    "output_dir = \"../output\"\n",
    "\n",
    "file_type = input(\"Enter input file type (csv or parquet): \").lower().strip()\n",
    "input_data_dir = os.path.join(input_data_dir, file_type)\n",
    "input_files = os.listdir(input_data_dir)\n",
    "\n",
    "df = spark.table(\"demo.nyc.taxis_1000_50_product\")\n",
    "records_before_op = df.count()\n",
    "\n",
    "for file in input_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    file_path = os.path.join(input_data_dir, file)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Read Data\n",
    "    if file_type == \"parquet\":\n",
    "        df = spark.read.parquet(file_path)\n",
    "    else:\n",
    "        df = spark.read.csv(file_path, header=True)\n",
    "        df = df.select(\n",
    "            *[F.col(f\"extra_col_{i}\").cast(\"string\" if i % 4 == 0 or i % 4 == 2 else \"int\" if i % 4 == 1 else \"date\") for i in range(50)]\n",
    "        )\n",
    "    \n",
    "    # Ensure extra_col_3 is in DATE format\n",
    "    df = df.withColumn(\"extra_col_3\", F.to_date(F.col(\"extra_col_3\")))\n",
    "\n",
    "    # Insert into Iceberg\n",
    "    df.writeTo(\"demo.nyc.taxis_1000_50_product\").append()\n",
    "\n",
    "    print(f\"Inserted {df.count()} records in {time.time() - start_time:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862cfa16-cb06-4815-926a-b8e2129bc0fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mSELECT\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mextra_col_2 , sum(extra_col_1)\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mFROM demo.nyc.taxis_1000_50_product\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mgorup by extra_col_2\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Execute the SQL query\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39msql(query)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Stop the timer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the complex SQL query for 'nyc.taxis_10000_50COLUMNS'\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "extra_col_2 , sum(extra_col_1)\n",
    "FROM demo.nyc.taxis_1000_50_product\n",
    "gorup by extra_col_2\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "df = spark.sql(query)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Show the result\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Print the time taken for the query\n",
    "print(f\"Time taken for the query: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5a28e02-7647-4b3f-bb71-14e722054298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|extra_col_2|extra_col_1|\n",
      "+-----------+-----------+\n",
      "|CAR        |1442       |\n",
      "|CAR        |8814       |\n",
      "|CAR        |5222       |\n",
      "|CAR        |9941       |\n",
      "|CAR        |7996       |\n",
      "|CAR        |9603       |\n",
      "|CAR        |8500       |\n",
      "|CAR        |895        |\n",
      "|CAR        |659        |\n",
      "|CAR        |7755       |\n",
      "|CAR        |6260       |\n",
      "|CAR        |3548       |\n",
      "|CAR        |3899       |\n",
      "|CAR        |2581       |\n",
      "|CAR        |487        |\n",
      "|CAR        |5077       |\n",
      "|CAR        |2962       |\n",
      "|CAR        |4863       |\n",
      "|CAR        |7316       |\n",
      "|CAR        |3765       |\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken for the query: 0.03855299949645996 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the complex SQL query for 'nyc.taxis_10000_50COLUMNS'\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "extra_col_2 , extra_col_1\n",
    "FROM demo.nyc.taxis_1000_50_product\n",
    "where extra_col_2 = 'CAR'\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "df = spark.sql(query)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Show the result\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Print the time taken for the query\n",
    "print(f\"Time taken for the query: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf1cf45b-a9c9-43dc-8ff4-52f467263cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+-------+------------+------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------+-------------+------------+-------------+--------------------+\n",
      "|content|           file_path|file_format|spec_id|record_count|file_size_in_bytes|        column_sizes|        value_counts|   null_value_counts|nan_value_counts|        lower_bounds|        upper_bounds|key_metadata|split_offsets|equality_ids|sort_order_id|    readable_metrics|\n",
      "+-------+--------------------+-----------+-------+------------+------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------+-------------+------------+-------------+--------------------+\n",
      "|      0|s3://warehouse/ny...|    PARQUET|      0|        1000|            251387|{1 -> 6751, 2 -> ...|{1 -> 1000, 2 -> ...|{1 -> 0, 2 -> 0, ...|              {}|{1 -> [41 41 4E 5...|{1 -> [5A 5A 53 5...|        NULL|          [4]|        NULL|            0|{{6751, 1000, 0, ...|\n",
      "|      0|s3://warehouse/ny...|    PARQUET|      0|         250|             49144|{1 -> 1693, 2 -> ...|{1 -> 250, 2 -> 2...|{1 -> 0, 2 -> 0, ...|              {}|{1 -> [41 44 59 4...|{1 -> [5A 5A 50 4...|        NULL|          [4]|        NULL|            0|{{1693, 250, 0, N...|\n",
      "|      0|s3://warehouse/ny...|    PARQUET|      0|         250|             49158|{1 -> 1712, 2 -> ...|{1 -> 250, 2 -> 2...|{1 -> 0, 2 -> 0, ...|              {}|{1 -> [41 42 58 5...|{1 -> [5A 59 54 4...|        NULL|          [4]|        NULL|            0|{{1712, 250, 0, N...|\n",
      "|      0|s3://warehouse/ny...|    PARQUET|      0|         250|             49155|{1 -> 1694, 2 -> ...|{1 -> 250, 2 -> 2...|{1 -> 0, 2 -> 0, ...|              {}|{1 -> [41 46 58 4...|{1 -> [5A 5A 4A 5...|        NULL|          [4]|        NULL|            0|{{1694, 250, 0, N...|\n",
      "|      0|s3://warehouse/ny...|    PARQUET|      0|         250|             49142|{1 -> 1713, 2 -> ...|{1 -> 250, 2 -> 2...|{1 -> 0, 2 -> 0, ...|              {}|{1 -> [41 43 5A 4...|{1 -> [5A 5A 58 4...|        NULL|          [4]|        NULL|            0|{{1713, 250, 0, N...|\n",
      "+-------+--------------------+-----------+-------+------------+------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------+-------------+------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM demo.nyc.taxis_1000_50_product.files\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44a59adc-2d35-46d2-bdac-153e26e3d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----------------------------+----------------------------+--------------------------+----------------------------+--------------------------+--------------------+------------------------+\n",
      "|record_count|file_count|total_data_file_size_in_bytes|position_delete_record_count|position_delete_file_count|equality_delete_record_count|equality_delete_file_count|     last_updated_at|last_updated_snapshot_id|\n",
      "+------------+----------+-----------------------------+----------------------------+--------------------------+----------------------------+--------------------------+--------------------+------------------------+\n",
      "|        2000|         5|                       447986|                           0|                         0|                           0|                         0|2025-02-28 12:18:...|        7066983146250631|\n",
      "+------------+----------+-----------------------------+----------------------------+--------------------------+----------------------------+--------------------------+--------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"SELECT * FROM demo.nyc.taxis_1000_50_product.partitions\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0a764a6-bb7b-433a-9e0e-e3bf845e6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.sql(\"CREATE TABLE demo.nyc.taxis_1000_50_product_partitioned USING ICEBERG PARTITIONED BY (extra_col_2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c10d257f-7f8b-4166-ad19-aed84875683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|col_name    |data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|extra_col_0 |string   |NULL   |\n",
      "|extra_col_1 |int      |NULL   |\n",
      "|extra_col_2 |string   |NULL   |\n",
      "|extra_col_3 |date     |NULL   |\n",
      "|extra_col_4 |string   |NULL   |\n",
      "|extra_col_5 |int      |NULL   |\n",
      "|extra_col_6 |string   |NULL   |\n",
      "|extra_col_7 |date     |NULL   |\n",
      "|extra_col_8 |string   |NULL   |\n",
      "|extra_col_9 |int      |NULL   |\n",
      "|extra_col_10|string   |NULL   |\n",
      "|extra_col_11|date     |NULL   |\n",
      "|extra_col_12|string   |NULL   |\n",
      "|extra_col_13|int      |NULL   |\n",
      "|extra_col_14|string   |NULL   |\n",
      "|extra_col_15|date     |NULL   |\n",
      "|extra_col_16|string   |NULL   |\n",
      "|extra_col_17|int      |NULL   |\n",
      "|extra_col_18|string   |NULL   |\n",
      "|extra_col_19|date     |NULL   |\n",
      "+------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FORMATTED demo.nyc.taxis_1000_50_product\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d761c000-e16f-483a-a354-5abee2a969de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|extra_col_2|\n",
      "+-----------+\n",
      "|CAR        |\n",
      "|CV         |\n",
      "|TW         |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT extra_col_2 FROM demo.nyc.taxis_1000_50_product_partitioned\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a30758ce-d4ba-44e1-b476-8247f45d1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for partitioning and saving the table: 1.353022813796997 seconds\n",
      "+-----------+\n",
      "|extra_col_2|\n",
      "+-----------+\n",
      "|CAR        |\n",
      "|CV         |\n",
      "|TW         |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the DataFrame from the existing table\n",
    "df = spark.table(\"demo.nyc.taxis_1000_50_product\")\n",
    "\n",
    "# Overwrite the existing partitioned table\n",
    "df.write.partitionBy(\"extra_col_2\").mode(\"overwrite\").saveAsTable(\"demo.nyc.taxis_1000_50_product_partitioned\")\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the time taken for the partitioning and saving process\n",
    "print(f\"Time taken for partitioning and saving the table: {end_time - start_time} seconds\")\n",
    "\n",
    "# Verify partitioning by showing distinct values of the partition column 'extra_col_2'\n",
    "df.select(\"extra_col_2\").distinct().show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1d7df-2f3c-4821-ace6-d70f53abc945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969dace0-dedc-47aa-9163-25210d2264e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
