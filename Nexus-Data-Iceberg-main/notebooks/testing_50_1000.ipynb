{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae4deab-63e0-4d23-b8ec-0c5bfda89978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"records\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd037161-60f7-4abd-a50d-ac82dba52a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|      nyc|           taxis_100|      false|\n",
      "|      nyc|            taxis_1B|      false|\n",
      "|      nyc|            taxis_1L|      false|\n",
      "|      nyc|          taxis_1000|      false|\n",
      "|      nyc|            taxis_10|      false|\n",
      "|      nyc| taxis_10M_50COLUMNS|      false|\n",
      "|      nyc|   taxis_1L_5COLUMNS|      false|\n",
      "|      nyc|         taxis_10000|      false|\n",
      "|      nyc|            taxis_1M|      false|\n",
      "|      nyc|          taxis_1L_5|      false|\n",
      "|      nyc|          taxis_10_M|      false|\n",
      "|      nyc|taxis_1000_50COLU...|      false|\n",
      "|      nyc|  taxis_10_50COLUMNS|      false|\n",
      "|      nyc|           taxis_10K|      false|\n",
      "|      nyc|taxis_100000_50CO...|      false|\n",
      "|      nyc|            taxis_1K|      false|\n",
      "|      nyc|           taxis_10L|      false|\n",
      "|      nyc|        taxis_5_100M|      false|\n",
      "|      nyc|           taxis_10M|      false|\n",
      "|      nyc|taxis_1000_50COLUMNS|      false|\n",
      "+---------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Switch to the 'nyc' database\n",
    "spark.sql(\"USE nyc\")\n",
    "\n",
    "# List all tables in the 'nyc' database\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb57cc93-16bd-4c24-9212-c227e99ae9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/25 18:43:57 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/02/25 18:43:57 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/02/25 18:44:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/02/25 18:44:14 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.6\n",
      "25/02/25 18:44:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|col_name    |data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|extra_col_0 |string   |NULL   |\n",
      "|extra_col_1 |int      |NULL   |\n",
      "|extra_col_2 |string   |NULL   |\n",
      "|extra_col_3 |date     |NULL   |\n",
      "|extra_col_4 |string   |NULL   |\n",
      "|extra_col_5 |int      |NULL   |\n",
      "|extra_col_6 |string   |NULL   |\n",
      "|extra_col_7 |date     |NULL   |\n",
      "|extra_col_8 |string   |NULL   |\n",
      "|extra_col_9 |int      |NULL   |\n",
      "|extra_col_10|string   |NULL   |\n",
      "|extra_col_11|date     |NULL   |\n",
      "|extra_col_12|string   |NULL   |\n",
      "|extra_col_13|int      |NULL   |\n",
      "|extra_col_14|string   |NULL   |\n",
      "|extra_col_15|date     |NULL   |\n",
      "|extra_col_16|string   |NULL   |\n",
      "|extra_col_17|int      |NULL   |\n",
      "|extra_col_18|string   |NULL   |\n",
      "|extra_col_19|date     |NULL   |\n",
      "+------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Spark SQL to describe the table and see its columns\n",
    "spark.sql(\"DESCRIBE nyc.taxis_1000_50COLUMNS\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca87b7f-d04c-4eb6-a8d8-db27d2705f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/25 11:37:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|extra_col_0|extra_col_1|extra_col_2    |extra_col_3|extra_col_4|extra_col_5|extra_col_6    |extra_col_7|extra_col_8|extra_col_9|extra_col_10   |extra_col_11|extra_col_12|extra_col_13|extra_col_14   |extra_col_15|extra_col_16|extra_col_17|extra_col_18   |extra_col_19|extra_col_20|extra_col_21|extra_col_22   |extra_col_23|extra_col_24|extra_col_25|extra_col_26   |extra_col_27|extra_col_28|extra_col_29|extra_col_30   |extra_col_31|extra_col_32|extra_col_33|extra_col_34   |extra_col_35|extra_col_36|extra_col_37|extra_col_38   |extra_col_39|extra_col_40|extra_col_41|extra_col_42   |extra_col_43|extra_col_44|extra_col_45|extra_col_46   |extra_col_47|extra_col_48|extra_col_49|\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|CRVJYYFPRY |3405       |VHHGQHQDNMLMIPS|2017-07-08 |EHZCMVTYTR |6011       |PZDNHBTEJHUIFER|2017-03-19 |MPTVSDKRWI |7538       |QSZXRCZQDMMERBV|2017-02-01  |NUWRTQHZVV  |8265        |HYQFXWKEJQGWIIO|2020-07-18  |BDQMDEAWWT  |6151        |FZLOSWRWFGPGJPY|2022-05-03  |JLDHZUWJZF  |7415        |VQPNVOEYZEHPAAO|2015-08-08  |KAKFZOAYII  |1381        |HBGHKXMXOYDDHTP|2020-08-22  |OVLPLOSMES  |5376        |QHMUTENGRMPYXJM|2019-05-15  |SZEVCAXDGQ  |3266        |NBREANDKYAJEQIL|2020-04-12  |ZYBZQERESV  |8834        |OANCJRHRNWTIZCP|2016-10-20  |TUZMJVVYHP  |4471        |XEXDVCTDMUJNSKU|2023-01-23  |TTJFJKQBFA  |8014        |MLZIXNJYRIVRWAI|2019-02-04  |QEABXWFKMP  |2650        |\n",
      "|ZEVLBWPGQJ |6080       |SUOPKZFESSIWDIK|2024-11-04 |EOEXFTCYQY |1005       |SFLWNPFPESYQWMS|2015-03-16 |TQBNMXCXBG |7449       |WHPUWPNIHFDDZWL|2016-05-21  |OZOHEUGTJJ  |156         |DLIVXKMLTUVTNVB|2017-07-20  |TWZJUTWMCT  |1198        |ARDJCYAOBGABCPQ|2019-06-13  |RFNIRMFACI  |4400        |QMHNATZVXWENFEI|2024-10-19  |YGRMLPRUVU  |7722        |LBJTHRNQUAUXERA|2016-04-05  |OGOQUILPBV  |3728        |YGYPJOMHKCLXCJU|2023-08-19  |MAQBDKWESA  |4934        |RJYNEDEPGGMFNIQ|2019-04-06  |SMADYJNTCL  |9976        |CSXDQLXHSISZZBG|2020-01-13  |ZWPGPLRLLD  |7943        |CZMLTVPUYYFEQNZ|2024-01-05  |UCDGFSACQY  |4087        |YBGGQELRIQJYBCG|2024-06-14  |JSYEADUWSP  |298         |\n",
      "|ESTOMZIZJS |7655       |XTMQERCZSOJXIEQ|2020-02-26 |PSGSMRGEFC |185        |IKSWPIPJTFRCAPM|2022-01-29 |PIRPFLNTSV |5045       |CSKIFKPNFVMPFAO|2021-03-20  |XVAVGZDMKO  |8084        |CCAKAQWSCTLGUCY|2017-03-03  |BOAZBTOCUF  |6811        |LYHIKSZPZCBRNSJ|2016-07-13  |RVBCOZAMDE  |8822        |PXSKFCLZZQRRTKW|2016-10-05  |FLUCNFNMFE  |2266        |VOWZICJEVPDKMWO|2017-12-06  |USCBGILZUI  |5251        |WLOKHDJWXSZSITE|2015-07-05  |BBGZRONGRG  |8938        |HKTKAXXJIBTCBUE|2017-05-13  |RXTIBGTUNY  |6989        |UNYUUQPBTYEYKMV|2020-01-14  |JVOPTTYSYG  |6315        |CMCDAVDVYBBOMDN|2022-07-17  |DGCGFFSJIS  |4781        |SPXFPARBAZTHRDH|2019-10-07  |QKXERJXMAU  |1327        |\n",
      "|MNEFJUDFRU |2319       |UABZVIIKRDPBEVB|2016-01-08 |JFUPERNUAD |817        |NGPPXDHEIDNZYEP|2023-07-25 |KSRLXACVJP |772        |MRMSLMPOQDSIREV|2017-05-28  |SPIGXYAMKO  |5005        |NWBCYYFPVKRDRYU|2019-07-24  |HSSVEINPMN  |4513        |VXGXXQHCUXZMRUI|2016-09-22  |NXLMRFXRVJ  |2489        |BGHMBRUEHQVNTPE|2021-07-08  |INHDTTUATX  |1271        |EORXHVEAEPWNFJH|2018-12-21  |HSIYBSXWRW  |1519        |FDTAFBHYHOVCLFQ|2020-02-03  |AOWWWMDZEV  |5531        |ATEVUXMXPRZEOVE|2022-05-10  |PHALBHWQZD  |8957        |KCZYBAVQDYAHEKZ|2024-11-12  |YZLBICSNBH  |1813        |HCGNFIGJTDRHTUU|2022-02-16  |XMPTHRPGPA  |9616        |XAIFPRUHIZFHREA|2017-12-31  |YEPNWISIUC  |290         |\n",
      "|QZICPJYGYS |3172       |FPVZIQDURFYAICG|2020-02-27 |LAGCOCZDZU |8085       |HCUWSFXFQEWTJYT|2018-11-04 |QBWHBOIZDO |6572       |JFHHLULQOYJGMIU|2019-04-29  |AIIUFEQUEO  |5838        |LBZCFDANBFLWNDB|2019-10-25  |XDNVCSJTDS  |9865        |YMOIJBPFAYOPUYV|2019-08-31  |NIRBVUZUQM  |6312        |QWENGXAZEFBBACL|2024-06-06  |CTGOHEJXZF  |3457        |VSBJZIYPROBEWIQ|2020-06-26  |PKMSUTCONU  |212         |VFXKMFQXWOVOGQS|2018-07-12  |FQUNKMRBVA  |905         |HMQNZPGRTGHGXCK|2016-09-30  |BDLXUVNNLJ  |8503        |BPYOHSTVOMNBQWC|2016-05-15  |WLJYUCDGIM  |8852        |ANSVCKXHNNGGSSJ|2016-03-07  |LMKCPGIIHE  |9367        |HRPWFVKLDAWWZBN|2018-09-18  |DQQAYCSOKN  |8600        |\n",
      "|SEATAXWGIO |1762       |HNMMWGBNTWTNKRA|2023-07-31 |XIRJAIOAGJ |6748       |WRBEBOGRSNZFNJL|2020-12-10 |ZFRZGXUZZX |8322       |DAOGZISJPCXNSKV|2018-02-26  |MKKGLUXUJC  |3882        |CGYYIMXXEWEIFKN|2019-03-11  |GVPQYWZGTR  |9203        |BZROEMGIPGBCULU|2015-09-19  |NSNJKTCQSH  |8950        |DBTWMXPVLXYGVEZ|2020-09-20  |UXBJIXFULV  |8805        |WDGAGNBYNGKOCDX|2022-12-26  |KPRFZBHBQS  |3396        |ORIBSCCFSHCAICW|2016-05-21  |LAUHNGPNWY  |8719        |PHVIUTIWQEPIQWQ|2023-10-17  |UZQMOAQTZO  |4728        |MOIPFSBXOOXBUEW|2020-10-13  |ZBZBJVYZQK  |135         |KHLWROGDACAPYQB|2019-05-27  |STCLPYXYMQ  |7427        |RXRUEEBUNRFIGZR|2023-04-29  |TUGKKSLEWY  |7473        |\n",
      "|FDQKGJNHQV |8611       |AODVESKGNLHNBII|2016-12-09 |RETPGRVXGA |7994       |DPCEHFUHPCOZRXA|2023-03-04 |GLMGEZZQSQ |3614       |YLCBYGMRAYLKXPI|2019-03-06  |UVBJFWHQIO  |5241        |BNAPFATSKQFCZKG|2025-02-19  |GOQLRKBIFI  |7388        |GBXVNUKEDOQWJXX|2024-10-10  |YCPKSGOCBR  |4584        |IEMECLIZLLAGONB|2015-08-19  |QXOHYPCJWP  |6027        |OPBDPKJXCRMKAHQ|2019-05-29  |PAZYCHQXEX  |1211        |KJMUGOXASXNLDYL|2023-09-24  |BATYVQTGSX  |6250        |VKACEMAVWEVRCXZ|2023-01-21  |PDRFWXHSWD  |8260        |UAGBNDPWJFPKITG|2024-07-23  |DLSMKPLEHS  |5960        |DKWZNLYUFYHHBBI|2020-09-08  |GDMHOSTFEC  |8409        |YFJDUQGBIWVTZZU|2023-02-05  |GXCFDICRJI  |9023        |\n",
      "|SHYLFLCXUN |8691       |PVLUCIJDGGIPZLH|2017-07-30 |GUYGMFXXYP |7327       |LQSBBIOVZHJTRIN|2024-11-22 |GMDNJYPOMJ |4050       |GEUNUOCBUWHQANT|2023-09-29  |NQCZUFPHWU  |815         |UVETRMLFAHPWYDS|2021-11-20  |PEYCTFQNTC  |9721        |BFDEYOIYUUOWRWW|2017-06-19  |PRKUVPMQGU  |7763        |QCVDTSYQNYLPVHO|2017-05-26  |FGZHPXEPDK  |842         |HEFFDQNFKBENAML|2020-07-07  |CXZMGKEVUK  |9926        |OZKZKMFWMFTMTWC|2020-09-12  |FHGKEZDGXQ  |4744        |HADFVZSCYJUISJM|2021-03-10  |YIMYULDZKX  |812         |EYJERBUZFOUMRMY|2015-08-27  |RMSEHMNKXK  |6121        |MKNSZABMOLBCQYO|2022-01-22  |RZRICVJABR  |5231        |GRGHBKZUJQKOKEO|2017-12-23  |ZQXNBNGYKG  |3712        |\n",
      "|JMSZWNEWYO |7634       |HDSCITKVZBZUASD|2024-12-25 |LWZKBTYPBK |7654       |OKURSCZLNSTOJAT|2024-10-07 |VBRCEIQTEW |3938       |KTQMVTLDLTVZRSA|2019-12-25  |JOSLHMXESN  |5561        |XUALXESBZMRIGFR|2019-08-22  |RQEJQGUXFN  |4859        |JMCQBJIOIIBUJRT|2022-10-21  |YOLQVZNCON  |1381        |CSESTEMFHTQTZUV|2018-05-29  |MHTXSJUIDX  |5371        |KVBOVFOUNMKBYOB|2018-08-21  |ZZJXQIOYJK  |2472        |HIEAPRZZMAULJXE|2024-01-23  |GFHKCOOILT  |7840        |FDGXEBUUVQCLLQD|2023-08-23  |CWELYAZEMP  |4155        |EUCCOMRDTDUDMPN|2024-04-17  |TFUYCRCWLP  |7130        |XDEOOGYURWSOSDS|2021-04-28  |GASSQLSKKY  |3080        |MAEHYLKOEFJTQSN|2020-02-07  |GHBQZAHGEZ  |7908        |\n",
      "|MHDNKBFBPZ |4004       |VZBUSMZSYNGWYXN|2018-04-24 |RPGFRHYFGA |6193       |HGIWGYUGJBVOWWB|2017-03-15 |ZMJZHLDSAP |7491       |LRTFLCEJQMCYJLE|2022-03-29  |LASUBDATIG  |8038        |GDRYHVCZNROJVWK|2023-03-13  |MSXIIFWYNK  |1088        |FENDBZFAXAACEKF|2022-01-28  |AUNUYCQQUV  |4069        |SJDJSFLVNBMKCBC|2018-01-08  |NKZKSFGBHF  |842         |GRJGTUKNFAHWXYQ|2020-11-23  |WGCNYAHMOY  |3553        |ZRIWAGPZQQLPWTD|2016-03-18  |UNOOMJQOFL  |9623        |LUNKGTRLJKBWLPN|2021-02-16  |LMQWBZQUMF  |8195        |RSPPSLRSYJBNVWW|2015-08-31  |KIHKWXWFVW  |4662        |XKZTDGYXEOEALRN|2022-01-04  |JFKTNRATQF  |1385        |CKTXGUJMUFNLBVN|2021-06-11  |GEGVTNSPMS  |5136        |\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nyc.taxis_1000_50COLUMNS LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc1fd11-9b00-41ff-85bb-91485955a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|extra_col_0|extra_col_1|extra_col_2    |extra_col_3|extra_col_4|extra_col_5|extra_col_6    |extra_col_7|extra_col_8|extra_col_9|extra_col_10   |extra_col_11|extra_col_12|extra_col_13|extra_col_14   |extra_col_15|extra_col_16|extra_col_17|extra_col_18   |extra_col_19|extra_col_20|extra_col_21|extra_col_22   |extra_col_23|extra_col_24|extra_col_25|extra_col_26   |extra_col_27|extra_col_28|extra_col_29|extra_col_30   |extra_col_31|extra_col_32|extra_col_33|extra_col_34   |extra_col_35|extra_col_36|extra_col_37|extra_col_38   |extra_col_39|extra_col_40|extra_col_41|extra_col_42   |extra_col_43|extra_col_44|extra_col_45|extra_col_46   |extra_col_47|extra_col_48|extra_col_49|\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|CRVJYYFPRY |3405       |VHHGQHQDNMLMIPS|2017-07-08 |EHZCMVTYTR |6011       |PZDNHBTEJHUIFER|2017-03-19 |MPTVSDKRWI |7538       |QSZXRCZQDMMERBV|2017-02-01  |NUWRTQHZVV  |8265        |HYQFXWKEJQGWIIO|2020-07-18  |BDQMDEAWWT  |6151        |FZLOSWRWFGPGJPY|2022-05-03  |JLDHZUWJZF  |7415        |VQPNVOEYZEHPAAO|2015-08-08  |KAKFZOAYII  |1381        |HBGHKXMXOYDDHTP|2020-08-22  |OVLPLOSMES  |5376        |QHMUTENGRMPYXJM|2019-05-15  |SZEVCAXDGQ  |3266        |NBREANDKYAJEQIL|2020-04-12  |ZYBZQERESV  |8834        |OANCJRHRNWTIZCP|2016-10-20  |TUZMJVVYHP  |4471        |XEXDVCTDMUJNSKU|2023-01-23  |TTJFJKQBFA  |8014        |MLZIXNJYRIVRWAI|2019-02-04  |QEABXWFKMP  |2650        |\n",
      "|ZEVLBWPGQJ |6080       |SUOPKZFESSIWDIK|2024-11-04 |EOEXFTCYQY |1005       |SFLWNPFPESYQWMS|2015-03-16 |TQBNMXCXBG |7449       |WHPUWPNIHFDDZWL|2016-05-21  |OZOHEUGTJJ  |156         |DLIVXKMLTUVTNVB|2017-07-20  |TWZJUTWMCT  |1198        |ARDJCYAOBGABCPQ|2019-06-13  |RFNIRMFACI  |4400        |QMHNATZVXWENFEI|2024-10-19  |YGRMLPRUVU  |7722        |LBJTHRNQUAUXERA|2016-04-05  |OGOQUILPBV  |3728        |YGYPJOMHKCLXCJU|2023-08-19  |MAQBDKWESA  |4934        |RJYNEDEPGGMFNIQ|2019-04-06  |SMADYJNTCL  |9976        |CSXDQLXHSISZZBG|2020-01-13  |ZWPGPLRLLD  |7943        |CZMLTVPUYYFEQNZ|2024-01-05  |UCDGFSACQY  |4087        |YBGGQELRIQJYBCG|2024-06-14  |JSYEADUWSP  |298         |\n",
      "|ESTOMZIZJS |7655       |XTMQERCZSOJXIEQ|2020-02-26 |PSGSMRGEFC |185        |IKSWPIPJTFRCAPM|2022-01-29 |PIRPFLNTSV |5045       |CSKIFKPNFVMPFAO|2021-03-20  |XVAVGZDMKO  |8084        |CCAKAQWSCTLGUCY|2017-03-03  |BOAZBTOCUF  |6811        |LYHIKSZPZCBRNSJ|2016-07-13  |RVBCOZAMDE  |8822        |PXSKFCLZZQRRTKW|2016-10-05  |FLUCNFNMFE  |2266        |VOWZICJEVPDKMWO|2017-12-06  |USCBGILZUI  |5251        |WLOKHDJWXSZSITE|2015-07-05  |BBGZRONGRG  |8938        |HKTKAXXJIBTCBUE|2017-05-13  |RXTIBGTUNY  |6989        |UNYUUQPBTYEYKMV|2020-01-14  |JVOPTTYSYG  |6315        |CMCDAVDVYBBOMDN|2022-07-17  |DGCGFFSJIS  |4781        |SPXFPARBAZTHRDH|2019-10-07  |QKXERJXMAU  |1327        |\n",
      "|MNEFJUDFRU |2319       |UABZVIIKRDPBEVB|2016-01-08 |JFUPERNUAD |817        |NGPPXDHEIDNZYEP|2023-07-25 |KSRLXACVJP |772        |MRMSLMPOQDSIREV|2017-05-28  |SPIGXYAMKO  |5005        |NWBCYYFPVKRDRYU|2019-07-24  |HSSVEINPMN  |4513        |VXGXXQHCUXZMRUI|2016-09-22  |NXLMRFXRVJ  |2489        |BGHMBRUEHQVNTPE|2021-07-08  |INHDTTUATX  |1271        |EORXHVEAEPWNFJH|2018-12-21  |HSIYBSXWRW  |1519        |FDTAFBHYHOVCLFQ|2020-02-03  |AOWWWMDZEV  |5531        |ATEVUXMXPRZEOVE|2022-05-10  |PHALBHWQZD  |8957        |KCZYBAVQDYAHEKZ|2024-11-12  |YZLBICSNBH  |1813        |HCGNFIGJTDRHTUU|2022-02-16  |XMPTHRPGPA  |9616        |XAIFPRUHIZFHREA|2017-12-31  |YEPNWISIUC  |290         |\n",
      "|QZICPJYGYS |3172       |FPVZIQDURFYAICG|2020-02-27 |LAGCOCZDZU |8085       |HCUWSFXFQEWTJYT|2018-11-04 |QBWHBOIZDO |6572       |JFHHLULQOYJGMIU|2019-04-29  |AIIUFEQUEO  |5838        |LBZCFDANBFLWNDB|2019-10-25  |XDNVCSJTDS  |9865        |YMOIJBPFAYOPUYV|2019-08-31  |NIRBVUZUQM  |6312        |QWENGXAZEFBBACL|2024-06-06  |CTGOHEJXZF  |3457        |VSBJZIYPROBEWIQ|2020-06-26  |PKMSUTCONU  |212         |VFXKMFQXWOVOGQS|2018-07-12  |FQUNKMRBVA  |905         |HMQNZPGRTGHGXCK|2016-09-30  |BDLXUVNNLJ  |8503        |BPYOHSTVOMNBQWC|2016-05-15  |WLJYUCDGIM  |8852        |ANSVCKXHNNGGSSJ|2016-03-07  |LMKCPGIIHE  |9367        |HRPWFVKLDAWWZBN|2018-09-18  |DQQAYCSOKN  |8600        |\n",
      "|SEATAXWGIO |1762       |HNMMWGBNTWTNKRA|2023-07-31 |XIRJAIOAGJ |6748       |WRBEBOGRSNZFNJL|2020-12-10 |ZFRZGXUZZX |8322       |DAOGZISJPCXNSKV|2018-02-26  |MKKGLUXUJC  |3882        |CGYYIMXXEWEIFKN|2019-03-11  |GVPQYWZGTR  |9203        |BZROEMGIPGBCULU|2015-09-19  |NSNJKTCQSH  |8950        |DBTWMXPVLXYGVEZ|2020-09-20  |UXBJIXFULV  |8805        |WDGAGNBYNGKOCDX|2022-12-26  |KPRFZBHBQS  |3396        |ORIBSCCFSHCAICW|2016-05-21  |LAUHNGPNWY  |8719        |PHVIUTIWQEPIQWQ|2023-10-17  |UZQMOAQTZO  |4728        |MOIPFSBXOOXBUEW|2020-10-13  |ZBZBJVYZQK  |135         |KHLWROGDACAPYQB|2019-05-27  |STCLPYXYMQ  |7427        |RXRUEEBUNRFIGZR|2023-04-29  |TUGKKSLEWY  |7473        |\n",
      "|FDQKGJNHQV |8611       |AODVESKGNLHNBII|2016-12-09 |RETPGRVXGA |7994       |DPCEHFUHPCOZRXA|2023-03-04 |GLMGEZZQSQ |3614       |YLCBYGMRAYLKXPI|2019-03-06  |UVBJFWHQIO  |5241        |BNAPFATSKQFCZKG|2025-02-19  |GOQLRKBIFI  |7388        |GBXVNUKEDOQWJXX|2024-10-10  |YCPKSGOCBR  |4584        |IEMECLIZLLAGONB|2015-08-19  |QXOHYPCJWP  |6027        |OPBDPKJXCRMKAHQ|2019-05-29  |PAZYCHQXEX  |1211        |KJMUGOXASXNLDYL|2023-09-24  |BATYVQTGSX  |6250        |VKACEMAVWEVRCXZ|2023-01-21  |PDRFWXHSWD  |8260        |UAGBNDPWJFPKITG|2024-07-23  |DLSMKPLEHS  |5960        |DKWZNLYUFYHHBBI|2020-09-08  |GDMHOSTFEC  |8409        |YFJDUQGBIWVTZZU|2023-02-05  |GXCFDICRJI  |9023        |\n",
      "|SHYLFLCXUN |8691       |PVLUCIJDGGIPZLH|2017-07-30 |GUYGMFXXYP |7327       |LQSBBIOVZHJTRIN|2024-11-22 |GMDNJYPOMJ |4050       |GEUNUOCBUWHQANT|2023-09-29  |NQCZUFPHWU  |815         |UVETRMLFAHPWYDS|2021-11-20  |PEYCTFQNTC  |9721        |BFDEYOIYUUOWRWW|2017-06-19  |PRKUVPMQGU  |7763        |QCVDTSYQNYLPVHO|2017-05-26  |FGZHPXEPDK  |842         |HEFFDQNFKBENAML|2020-07-07  |CXZMGKEVUK  |9926        |OZKZKMFWMFTMTWC|2020-09-12  |FHGKEZDGXQ  |4744        |HADFVZSCYJUISJM|2021-03-10  |YIMYULDZKX  |812         |EYJERBUZFOUMRMY|2015-08-27  |RMSEHMNKXK  |6121        |MKNSZABMOLBCQYO|2022-01-22  |RZRICVJABR  |5231        |GRGHBKZUJQKOKEO|2017-12-23  |ZQXNBNGYKG  |3712        |\n",
      "|JMSZWNEWYO |7634       |HDSCITKVZBZUASD|2024-12-25 |LWZKBTYPBK |7654       |OKURSCZLNSTOJAT|2024-10-07 |VBRCEIQTEW |3938       |KTQMVTLDLTVZRSA|2019-12-25  |JOSLHMXESN  |5561        |XUALXESBZMRIGFR|2019-08-22  |RQEJQGUXFN  |4859        |JMCQBJIOIIBUJRT|2022-10-21  |YOLQVZNCON  |1381        |CSESTEMFHTQTZUV|2018-05-29  |MHTXSJUIDX  |5371        |KVBOVFOUNMKBYOB|2018-08-21  |ZZJXQIOYJK  |2472        |HIEAPRZZMAULJXE|2024-01-23  |GFHKCOOILT  |7840        |FDGXEBUUVQCLLQD|2023-08-23  |CWELYAZEMP  |4155        |EUCCOMRDTDUDMPN|2024-04-17  |TFUYCRCWLP  |7130        |XDEOOGYURWSOSDS|2021-04-28  |GASSQLSKKY  |3080        |MAEHYLKOEFJTQSN|2020-02-07  |GHBQZAHGEZ  |7908        |\n",
      "|MHDNKBFBPZ |4004       |VZBUSMZSYNGWYXN|2018-04-24 |RPGFRHYFGA |6193       |HGIWGYUGJBVOWWB|2017-03-15 |ZMJZHLDSAP |7491       |LRTFLCEJQMCYJLE|2022-03-29  |LASUBDATIG  |8038        |GDRYHVCZNROJVWK|2023-03-13  |MSXIIFWYNK  |1088        |FENDBZFAXAACEKF|2022-01-28  |AUNUYCQQUV  |4069        |SJDJSFLVNBMKCBC|2018-01-08  |NKZKSFGBHF  |842         |GRJGTUKNFAHWXYQ|2020-11-23  |WGCNYAHMOY  |3553        |ZRIWAGPZQQLPWTD|2016-03-18  |UNOOMJQOFL  |9623        |LUNKGTRLJKBWLPN|2021-02-16  |LMQWBZQUMF  |8195        |RSPPSLRSYJBNVWW|2015-08-31  |KIHKWXWFVW  |4662        |XKZTDGYXEOEALRN|2022-01-04  |JFKTNRATQF  |1385        |CKTXGUJMUFNLBVN|2021-06-11  |GEGVTNSPMS  |5136        |\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "\n",
      "Time taken for the operation: 0.5980069637298584 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the Spark SQL query\n",
    "spark.sql(\"SELECT * FROM nyc.taxis_1000_50COLUMNS LIMIT 10\").show(truncate=False)\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Print the time taken\n",
    "print(f\"Time taken for the operation: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c898ebca-b6c5-40d5-8ba8-90070d6dc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|start_date|end_date  |\n",
      "+----------+----------+\n",
      "|2015-03-09|2025-02-22|\n",
      "+----------+----------+\n",
      "\n",
      "Time taken for the operation: 1.1512253284454346 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Query to get the first (start) and last (end) dates\n",
    "query = \"\"\"\n",
    "SELECT MIN(extra_col_3) AS start_date, MAX(extra_col_3) AS end_date\n",
    "FROM nyc.taxis_1000_50COLUMNS\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = spark.sql(query)\n",
    "\n",
    "# Show the result\n",
    "result.show(truncate=False)\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Print the time taken\n",
    "print(f\"Time taken for the operation: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ade04a-2d70-470b-bf11-7c7ce637dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/25 18:52:47 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 1000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter percentage of records to update:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 10 random records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/25 18:52:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/25 18:52:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/25 18:52:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/25 18:52:50 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully updated 10 random records!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"urecords\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# Define your table name\n",
    "table_name = \"demo.nyc.taxis_1000_50COLUMNS\"  # Change this to your actual table\n",
    "\n",
    "# Step 1: Get total records\n",
    "total_records = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "print(f\"Total records: {total_records}\")\n",
    "\n",
    "# Step 2: Percentage input\n",
    "percentage = float(input(\"Enter percentage of records to update: \"))\n",
    "\n",
    "# Step 3: Calculate records to update\n",
    "num_records_to_update = max(1, int((percentage / 100) * total_records))\n",
    "print(f\"Updating {num_records_to_update} random records.\")\n",
    "\n",
    "# Step 4: Select random records\n",
    "random_records_query = f\"\"\"\n",
    "SELECT extra_col_0 FROM (\n",
    "    SELECT extra_col_0, ROW_NUMBER() OVER (ORDER BY RAND()) as row_num\n",
    "    FROM {table_name}\n",
    ") WHERE row_num <= {num_records_to_update}\n",
    "\"\"\"\n",
    "random_records = spark.sql(random_records_query).collect()\n",
    "\n",
    "# Step 5: Function to generate random values with correct data types\n",
    "def generate_random_value(data_type):\n",
    "    \"\"\"Generate a random value based on the column's data type\"\"\"\n",
    "    data_type = data_type.lower()  # Convert to lowercase for comparison\n",
    "\n",
    "    if \"int\" in data_type or \"bigint\" in data_type or \"smallint\" in data_type:\n",
    "        return str(random.randint(1, 10000))  # Return as a number, no quotes\n",
    "    elif \"string\" in data_type or \"varchar\" in data_type or \"char\" in data_type:\n",
    "        return f\"'Random_{random.randint(100, 999)}'\"  # String needs quotes\n",
    "    elif \"date\" in data_type:\n",
    "        return f\"DATE('{(datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d')}')\"  # Ensure DATE format\n",
    "    elif \"timestamp\" in data_type:\n",
    "        return f\"TIMESTAMP('{(datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d %H:%M:%S')}')\"  # Timestamp format\n",
    "    elif \"double\" in data_type or \"float\" in data_type or \"decimal\" in data_type:\n",
    "        return str(round(random.uniform(1.0, 100.0), 2))  # Decimal values\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "# Step 6: Get table schema\n",
    "schema_df = spark.sql(f\"DESCRIBE {table_name}\")\n",
    "columns = {row[\"col_name\"]: row[\"data_type\"] for row in schema_df.collect() if not row[\"col_name\"].startswith(\"#\")}\n",
    "\n",
    "# Step 7: Execute updates for each random record\n",
    "for record in random_records:\n",
    "    record_id = record[\"extra_col_0\"]  # Assuming extra_col_0 is the primary key\n",
    "    update_statements = []\n",
    "\n",
    "    for col_name, col_type in columns.items():\n",
    "        if col_name == \"extra_col_0\":  # Skip primary key column\n",
    "            continue\n",
    "        new_value = generate_random_value(col_type)\n",
    "        update_statements.append(f\"{col_name} = {new_value}\")  # Ensure proper formatting\n",
    "\n",
    "    update_query = f\"UPDATE {table_name} SET {', '.join(update_statements)} WHERE extra_col_0 = '{record_id}'\"\n",
    "\n",
    "    try:\n",
    "        spark.sql(update_query)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error updating record {record_id}: {str(e)}\")\n",
    "\n",
    "print(f\"✅ Successfully updated {num_records_to_update} random records!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c17777-2b49-442e-befa-5fcb554193cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/25 18:54:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before update: 1000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter percentage of records to update:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 10 random records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/25 18:54:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/25 18:54:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/25 18:54:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after update: 1000\n",
      "✅ Successfully updated 10 random records!\n",
      "⏳ Total time taken: 16.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"update_random_records\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# Define your table name\n",
    "table_name = \"demo.nyc.taxis_1000_50COLUMNS\"  # Change this to your actual table\n",
    "\n",
    "# Step 1: Get total records before update\n",
    "start_time = time.time()\n",
    "total_records_before = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "print(f\"Total records before update: {total_records_before}\")\n",
    "\n",
    "# Step 2: Percentage input\n",
    "percentage = float(input(\"Enter percentage of records to update: \"))\n",
    "\n",
    "# Step 3: Calculate records to update\n",
    "num_records_to_update = max(1, int((percentage / 100) * total_records_before))\n",
    "print(f\"Updating {num_records_to_update} random records.\")\n",
    "\n",
    "# Step 4: Select random records\n",
    "random_records_query = f\"\"\"\n",
    "SELECT extra_col_0 FROM (\n",
    "    SELECT extra_col_0, ROW_NUMBER() OVER (ORDER BY RAND()) as row_num\n",
    "    FROM {table_name}\n",
    ") WHERE row_num <= {num_records_to_update}\n",
    "\"\"\"\n",
    "random_records = spark.sql(random_records_query).collect()\n",
    "\n",
    "# Step 5: Function to generate random values with correct data types\n",
    "def generate_random_value(data_type):\n",
    "    \"\"\"Generate a random value based on the column's data type\"\"\"\n",
    "    data_type = data_type.lower()\n",
    "\n",
    "    if \"int\" in data_type or \"bigint\" in data_type or \"smallint\" in data_type:\n",
    "        return str(random.randint(1, 10000))  # Return as a number, no quotes\n",
    "    elif \"string\" in data_type or \"varchar\" in data_type or \"char\" in data_type:\n",
    "        return f\"'Random_{random.randint(100, 999)}'\"  # String needs quotes\n",
    "    elif \"date\" in data_type:\n",
    "        return f\"DATE('{(datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d')}')\"\n",
    "    elif \"timestamp\" in data_type:\n",
    "        return f\"TIMESTAMP('{(datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d %H:%M:%S')}')\"\n",
    "    elif \"double\" in data_type or \"float\" in data_type or \"decimal\" in data_type:\n",
    "        return str(round(random.uniform(1.0, 100.0), 2))\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "# Step 6: Get table schema\n",
    "schema_df = spark.sql(f\"DESCRIBE {table_name}\")\n",
    "columns = {row[\"col_name\"]: row[\"data_type\"] for row in schema_df.collect() if not row[\"col_name\"].startswith(\"#\")}\n",
    "\n",
    "# Step 7: Execute updates for each random record\n",
    "for record in random_records:\n",
    "    record_id = record[\"extra_col_0\"]  # Assuming extra_col_0 is the primary key\n",
    "    update_statements = []\n",
    "\n",
    "    for col_name, col_type in columns.items():\n",
    "        if col_name == \"extra_col_0\":  # Skip primary key column\n",
    "            continue\n",
    "        new_value = generate_random_value(col_type)\n",
    "        update_statements.append(f\"{col_name} = {new_value}\")\n",
    "\n",
    "    update_query = f\"UPDATE {table_name} SET {', '.join(update_statements)} WHERE extra_col_0 = '{record_id}'\"\n",
    "\n",
    "    try:\n",
    "        spark.sql(update_query)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error updating record {record_id}: {str(e)}\")\n",
    "\n",
    "# Step 8: Get total records after update\n",
    "total_records_after = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "print(f\"Total records after update: {total_records_after}\")\n",
    "\n",
    "# Step 9: Print total time taken\n",
    "end_time = time.time()\n",
    "time_taken = round(end_time - start_time, 2)\n",
    "print(f\"✅ Successfully updated {num_records_to_update} random records!\")\n",
    "print(f\"⏳ Total time taken: {time_taken} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0cc74f-9dcb-4716-ba1a-2d5f458dcc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before update: 1000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter percentage of records to update & insert:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 10 random records.\n",
      "Inserting 10 new records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/25 19:00:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/25 19:00:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/02/25 19:00:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after update: 1010\n",
      "✅ Successfully updated 10 records & inserted 10 new records!\n",
      "⏳ Total time taken: 14.71 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"records\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# Define table name\n",
    "table_name = \"demo.nyc.taxis_1000_50COLUMNS\"  # Change this to your actual table\n",
    "\n",
    "# Step 1: Get total records before update\n",
    "start_time = time.time()\n",
    "total_records_before = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "print(f\"Total records before update: {total_records_before}\")\n",
    "\n",
    "# Step 2: Ask user input for update percentage\n",
    "update_percentage = float(input(\"Enter percentage of records to update & insert: \"))\n",
    "\n",
    "# Step 3: Calculate records to update & insert (same count)\n",
    "num_records = max(1, int((update_percentage / 100) * total_records_before))\n",
    "\n",
    "print(f\"Updating {num_records} random records.\")\n",
    "print(f\"Inserting {num_records} new records.\")\n",
    "\n",
    "# Step 4: Select random records for update\n",
    "random_records_query = f\"\"\"\n",
    "SELECT extra_col_0 FROM (\n",
    "    SELECT extra_col_0, ROW_NUMBER() OVER (ORDER BY RAND()) as row_num\n",
    "    FROM {table_name}\n",
    ") WHERE row_num <= {num_records}\n",
    "\"\"\"\n",
    "random_records = spark.sql(random_records_query).collect()\n",
    "\n",
    "# Step 5: Function to generate random values with correct data types\n",
    "def generate_random_value(data_type):\n",
    "    if \"int\" in data_type:\n",
    "        return str(random.randint(1, 10000))  # INT values\n",
    "    elif \"string\" in data_type:\n",
    "        return f\"'Random_{random.randint(100, 999)}'\"  # STRING values\n",
    "    elif \"date\" in data_type:\n",
    "        return f\"CAST('{(datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d')}' AS DATE)\"  # DATE values\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "# Step 6: Get table schema\n",
    "schema_df = spark.sql(f\"DESCRIBE {table_name}\")\n",
    "schema_dict = {row[\"col_name\"]: row[\"data_type\"] for row in schema_df.collect() if not row[\"col_name\"].startswith(\"#\")}\n",
    "columns = list(schema_dict.keys())\n",
    "\n",
    "# Step 7: Execute updates for each random record\n",
    "for record in random_records:\n",
    "    record_id = record[\"extra_col_0\"]  # Assuming extra_col_0 is the primary key\n",
    "    update_statements = []\n",
    "\n",
    "    for col_name in columns:\n",
    "        if col_name == \"extra_col_0\":  # Skip primary key column\n",
    "            continue\n",
    "        col_type = schema_dict[col_name]\n",
    "        new_value = generate_random_value(col_type)\n",
    "        update_statements.append(f\"{col_name} = {new_value}\")\n",
    "\n",
    "    update_query = f\"UPDATE {table_name} SET {', '.join(update_statements)} WHERE extra_col_0 = '{record_id}'\"\n",
    "    spark.sql(update_query)\n",
    "\n",
    "# Step 8: Insert new records (same count as updates)\n",
    "insert_values = []\n",
    "for _ in range(num_records):\n",
    "    values = []\n",
    "    for col_name in columns:\n",
    "        col_type = schema_dict[col_name]\n",
    "        values.append(generate_random_value(col_type))\n",
    "    insert_values.append(f\"({', '.join(values)})\")\n",
    "\n",
    "insert_query = f\"INSERT INTO {table_name} VALUES {', '.join(insert_values)}\"\n",
    "spark.sql(insert_query)\n",
    "\n",
    "# Step 9: Get total records after update\n",
    "total_records_after = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "\n",
    "# Step 10: Print final output\n",
    "end_time = time.time()\n",
    "print(f\"Total records after update: {total_records_after}\")\n",
    "print(f\"✅ Successfully updated {num_records} records & inserted {num_records} new records!\")\n",
    "print(f\"⏳ Total time taken: {round(end_time - start_time, 2)} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495a719-90c9-4c30-8baa-99b781a4602b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
