{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae4deab-63e0-4d23-b8ec-0c5bfda89978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"records\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd037161-60f7-4abd-a50d-ac82dba52a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|      nyc|           taxis_100|      false|\n",
      "|      nyc|     taxis_100M_time|      false|\n",
      "|      nyc|taxis_1000_50COLUMNS|      false|\n",
      "|      nyc|            taxis_1B|      false|\n",
      "|      nyc|            taxis_1L|      false|\n",
      "|      nyc|          taxis_1000|      false|\n",
      "|      nyc|            taxis_10|      false|\n",
      "|      nyc| taxis_10M_50COLUMNS|      false|\n",
      "|      nyc|   taxis_1L_5COLUMNS|      false|\n",
      "|      nyc|         taxis_10000|      false|\n",
      "|      nyc|            taxis_1M|      false|\n",
      "|      nyc|          taxis_1L_5|      false|\n",
      "|      nyc|          taxis_10_M|      false|\n",
      "|      nyc|taxis_1000_50COLU...|      false|\n",
      "|      nyc|  taxis_10_50COLUMNS|      false|\n",
      "|      nyc|           taxis_10K|      false|\n",
      "|      nyc|taxis_100000_50CO...|      false|\n",
      "|      nyc|            taxis_1K|      false|\n",
      "|      nyc|           taxis_10L|      false|\n",
      "|      nyc|        taxis_5_100M|      false|\n",
      "+---------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Switch to the 'nyc' database\n",
    "spark.sql(\"USE nyc\")\n",
    "\n",
    "# List all tables in the 'nyc' database\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb57cc93-16bd-4c24-9212-c227e99ae9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|col_name    |data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|extra_col_0 |string   |NULL   |\n",
      "|extra_col_1 |int      |NULL   |\n",
      "|extra_col_2 |string   |NULL   |\n",
      "|extra_col_3 |date     |NULL   |\n",
      "|extra_col_4 |string   |NULL   |\n",
      "|extra_col_5 |int      |NULL   |\n",
      "|extra_col_6 |string   |NULL   |\n",
      "|extra_col_7 |date     |NULL   |\n",
      "|extra_col_8 |string   |NULL   |\n",
      "|extra_col_9 |int      |NULL   |\n",
      "|extra_col_10|string   |NULL   |\n",
      "|extra_col_11|date     |NULL   |\n",
      "|extra_col_12|string   |NULL   |\n",
      "|extra_col_13|int      |NULL   |\n",
      "|extra_col_14|string   |NULL   |\n",
      "|extra_col_15|date     |NULL   |\n",
      "|extra_col_16|string   |NULL   |\n",
      "|extra_col_17|int      |NULL   |\n",
      "|extra_col_18|string   |NULL   |\n",
      "|extra_col_19|date     |NULL   |\n",
      "+------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Spark SQL to describe the table and see its columns\n",
    "spark.sql(\"DESCRIBE nyc.taxis_100M_50COLUMNS\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ca87b7f-d04c-4eb6-a8d8-db27d2705f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 462:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|extra_col_0|extra_col_1|extra_col_2    |extra_col_3|extra_col_4|extra_col_5|extra_col_6    |extra_col_7|extra_col_8|extra_col_9|extra_col_10   |extra_col_11|extra_col_12|extra_col_13|extra_col_14   |extra_col_15|extra_col_16|extra_col_17|extra_col_18   |extra_col_19|extra_col_20|extra_col_21|extra_col_22   |extra_col_23|extra_col_24|extra_col_25|extra_col_26   |extra_col_27|extra_col_28|extra_col_29|extra_col_30   |extra_col_31|extra_col_32|extra_col_33|extra_col_34   |extra_col_35|extra_col_36|extra_col_37|extra_col_38   |extra_col_39|extra_col_40|extra_col_41|extra_col_42   |extra_col_43|extra_col_44|extra_col_45|extra_col_46   |extra_col_47|extra_col_48|extra_col_49|\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|HNPTDXSVHW |669        |JNJMHTYVHAITOTK|2016-04-21 |KSCXQDLERE |5991       |TNCHHWKEMLBUOHY|2021-06-30 |KFGOBGVDKP |733        |UFUPERMJSLUVXML|2022-01-09  |IZDGRXFFPV  |1862        |MKFPBJORCJXRPWD|2016-12-25  |BLXYWGNPTX  |8816        |WNYXLPFGPWSTCWI|2021-05-17  |QHWPUOGGQC  |625         |QLKSOYFWMSCXKAT|2019-01-05  |AGBFJQIHWI  |1104        |NVBVSELTWVXGPON|2020-06-27  |FUDOPWAXKO  |969         |AENXMSKZYRSCZUO|2023-09-04  |CUEIIGXMSC  |7524        |PTTTEFBCLGKQAJA|2022-10-08  |SJLRGVZOWN  |9486        |OWDHIRNXVYHJFIH|2019-06-22  |ECZCEEJYZW  |149         |BKQCLMPQNQPQLVF|2017-08-20  |LMXYFTXFTC  |3219        |IRMAMGVYNJSGPFC|2021-01-07  |YEYVTPSQYQ  |1241        |\n",
      "|DBEFLXTUAO |2423       |EVSFWHYLVXYYMST|2017-12-26 |DUDTWXWNJJ |8985       |KVIMASLTFWUNZTU|2016-02-29 |SKSDXGSOMK |659        |WCOSPPDNLZWVEHG|2017-10-30  |ZLMEBIYSWW  |2390        |AGPUSXGPMBQJIKJ|2017-12-26  |CHBLKZRPSW  |2748        |VHNCQAFTLBIJHDD|2017-09-07  |QFMBHUTLKO  |6822        |YNHJCGBLZPSEVEY|2021-03-10  |HRDFWZHGOQ  |5985        |CEADAWBVIQAILJO|2018-01-22  |JRNEVCBQIK  |9920        |YIJKCWAOUTONQOP|2017-04-14  |BLWEJBWCEZ  |7291        |HRZHJEFDTVMHBBG|2020-07-17  |CJDLIQNXXP  |1103        |GJTUTSJYBYWFLWT|2022-07-28  |ZFSOUCFNUF  |8878        |QPLKFWUDOHAAKIX|2024-02-21  |GDRYCPSOGU  |1623        |NPFFHTEHYJSFCAZ|2016-02-09  |NJBPDVDASP  |3295        |\n",
      "|UYIWAZAUAD |3831       |OVYWHXCQWHHLCLI|2016-08-06 |JZXVFGSGLD |7153       |CYDCPGZPYEYYBWD|2016-09-15 |YGKIAKXTXP |1705       |XTUTWFIOLDZIZUB|2024-01-14  |LLSPNBHWEN  |2798        |WTIQSSTMLVUAZQJ|2016-04-29  |OKRIYHXYVE  |2536        |ZPNQSLOTZFYWWAH|2022-04-29  |LVXUYCSOOZ  |921         |APPKKUQFNINCAKK|2024-07-09  |SPUTQKHRIT  |648         |OYTOXBCOILEQDSG|2022-09-27  |KNTMZXIMLX  |6352        |HVWGLXFBVYNDFNH|2021-04-03  |XHAKYYDXWI  |743         |KXFOVOHXMEKPPMC|2019-03-26  |VZTOXUGURQ  |3594        |YEVAXEMHFYQTOWN|2021-10-11  |LZNPFDQKXY  |5950        |JKDXXJHESWFGIWM|2020-12-11  |NWMXAHEKZY  |5197        |AEENGKGXAYICNNP|2015-03-08  |ZIIQUCEZHW  |3969        |\n",
      "|QKVJAGLTRN |3424       |JBDWDXZBXNDLOUL|2022-07-20 |VEZPGEUAJO |8649       |CIWIXOSACOYBNTI|2019-09-12 |DUHZMOWBCI |8616       |DFKNOWVRSBLEPUK|2016-05-23  |WYYEDGQNXL  |8560        |UJQODGQLLRRXUEU|2018-12-01  |PTUTPCSLYE  |8771        |TCSYCGMOBMYTYLM|2023-04-07  |YVFQNMOSKV  |6505        |RMORSBXBLZZDIOO|2024-12-16  |CLAXDBOLDP  |8071        |FBEICTJQPMLXABG|2020-05-01  |OTDQACJMDE  |1216        |WDOSJGPIJCJAFGX|2016-03-25  |VBZCEWRHOB  |5488        |KHCDPOPGHYCEWMX|2017-05-19  |JEZFYUZHMA  |6445        |IEKWCDBLRJTDVBJ|2015-11-16  |RDHIHIBAAE  |6375        |YCSRCGRGEOQQMLC|2017-12-04  |FZUTPVHJMB  |8447        |ZXNBORRUKCPGICU|2021-09-20  |PYVAJBKJPR  |3907        |\n",
      "|DZKPIKGQWS |3886       |NINVFVDJFKJHYVG|2018-09-17 |FRKBYBAPES |4522       |NBSVOCWDZCHFXJA|2017-11-02 |TKIDWRVGFD |9134       |NZSGVDVDQQKKBGS|2024-01-28  |ERRJYMSVQY  |7621        |UTTNNSCIEKJFVRN|2020-04-21  |CFUYBLPKMK  |1973        |NBTWSBCYKMOSSQJ|2016-06-01  |CDYZILZIBD  |2403        |EQECILEQENHVCND|2020-11-14  |IXXTUTOXHL  |2788        |GGRWCQDAMOBKTFT|2022-10-06  |WKXFZGMWZK  |6000        |MYUZOCABIFOZYLZ|2019-04-10  |OEBZLEDGMF  |577         |IKXJJMVJSFLXGAQ|2024-12-03  |PFLKHRBUBU  |3062        |WZCPYPWJWZAVMAO|2024-08-24  |EKKYLHZXNM  |6092        |VEHRAWIKZAQARZS|2021-09-16  |XGFNKAYRFI  |4171        |JMAIHPZCXWVHJJL|2015-12-16  |GFMWLRFCXB  |1286        |\n",
      "|BLDCKXAINX |7141       |CAHXLDCNQZXZVQS|2017-05-30 |KWNQYJTYGO |2763       |YDUFRBTZWUWSBKD|2021-12-27 |JNHRTJRJEI |1197       |NWVERDMRIVZRKDL|2017-03-05  |WTTJZIHBMP  |3948        |HANOCRTPKYJAIFD|2017-02-23  |WFWPUEDXIV  |4080        |HERUBSHMDHMLXLF|2019-11-15  |TQHSKGEWGF  |3835        |DKBCSWALDNXZVZT|2017-05-22  |ZRYYYTYGJH  |7320        |PETVEZEIFAJPSRJ|2017-08-29  |MDGPAUXBUA  |7048        |ENTKDMAPFJNRHNI|2015-11-14  |PNLVBYKUTQ  |1669        |UMXASBWHRELTGJL|2020-09-20  |NYSDHLSBVY  |9393        |UHQGQSKPCOHDRZF|2016-04-12  |AGYLUGARFB  |564         |DLRBHGFSCZQBWXX|2021-12-14  |DQCICAQQRP  |8551        |EXXCLYQTPDVYEEI|2015-03-30  |MLXSWNTFDR  |7395        |\n",
      "|LIKSZASEVA |8117       |YFRKWGVLEFRDWYQ|2016-01-10 |ZQZFLLVMLX |3775       |HZONAOJXFPHEZXO|2023-05-30 |ZGMVJZZSUJ |9032       |MKBGJCZHBKERMFK|2021-03-07  |KRGMUFPOBC  |1713        |SAYYGBEQQLESEBX|2024-03-08  |GZQDLAPRBT  |9896        |RYVKELRPXPODMVG|2019-05-12  |TPAWVEPODE  |2894        |JOTCHJIMMDWHYKA|2017-09-05  |CWFJFQZNMI  |3510        |AVAGANWEXFDCTLU|2021-06-14  |EKPFWCBGFA  |7408        |BHJLGUGZNYHZIMS|2021-06-08  |UOESOSIIER  |5612        |MQVCAVHOFDVFVQW|2020-09-04  |XVNADXXEFR  |6571        |APDWSFWWPCRVNYU|2023-11-13  |AHUNRDHHOV  |1253        |WSTDBKXEMCFXRUR|2017-08-14  |VMBDTJMNLW  |5461        |BGOTIQODMJURWYG|2023-11-30  |YIUGQDIANJ  |6995        |\n",
      "|GDKWLPRVND |1982       |SHWGAJJDVJUVLIP|2023-01-01 |GTQOEBVICI |6689       |YMVOJQRQKHENXIO|2024-07-24 |VAJMXEHQNV |6230       |ADOQTYYBQKUIXVZ|2015-11-12  |VLIYTZPONU  |4290        |GFOBXHBSPEXMEPQ|2020-04-19  |OUHNGSPLUN  |8739        |DHAJXHHNHTZFMBK|2018-10-31  |LZRQWHUUNM  |5691        |RVZACWUYLDHJSSH|2015-09-16  |FOYHKKHTWK  |2830        |PHVBYDJVPJTZDTW|2021-07-08  |PKFRWAGBCL  |5368        |GXIGPOFOUEHUSPH|2018-02-01  |OGUHMYSMUE  |6093        |XIYUEIQPABNLIJG|2023-09-21  |LDCTGJJAKL  |5959        |HPNNVUTAHYKQELM|2024-06-27  |EUUNWNICZV  |2642        |JMXUDIACGYGZBGD|2015-12-07  |JTVSDLXCUQ  |6669        |MZHOOTKKNVDMLAB|2020-10-25  |FWWBERYNRB  |283         |\n",
      "|IXNLZVHELH |152        |MAJPDQBPPSZXYAF|2022-01-24 |MDYYVOCMAW |8407       |ODWUADUUNSKOEAP|2018-10-26 |KZJPEZRQFF |5881       |UDRCNYVAGDOUVDZ|2021-04-30  |BSUPNKGLGW  |6261        |MQVLHCFZJMFOHWH|2018-04-23  |LMAWOFAGKE  |3555        |UPVVWEEAPLNMBWN|2018-02-12  |RYNWGVBHVG  |1268        |KBHYJRJAIEUUCLU|2019-09-22  |NPNEJIMRCV  |5138        |ROZKQVOZTTJKWPV|2023-04-08  |UMRYBHWOWI  |6318        |YLNNEFSOKPFJIWE|2019-07-05  |AUUQTMIUQT  |1658        |SNTIKCCXVUGWDGN|2016-03-06  |PEXVMGEOED  |5422        |UHJDVHSWEFGVJFI|2017-12-15  |YXLGBIZYHC  |6207        |VFLMOFIWFEGOLVB|2019-10-15  |WIPXABZASC  |5724        |KQQJTUWBCAJYUVM|2018-08-11  |CXJOFSMSCX  |9473        |\n",
      "|VPLMMAEIOW |8090       |UCTNTAEZFKGEJNG|2019-06-30 |KCNOKZVBLC |2661       |BEGIBWLTMAJVRLC|2021-08-16 |NURKVXBGMW |6796       |YWMNJFJJEFHDJNV|2016-11-11  |BSPDCLWIDK  |8368        |ZQYBBFWDAHOTDEV|2015-03-26  |HKBVGPNGRV  |9293        |DPDIYIMGMMFJBQD|2022-09-24  |MVKMYUWCON  |504         |AQRSVAQUTHAZDOY|2016-02-14  |WNZUBHNDQL  |6509        |RKVNQIJSDLGQGIF|2023-07-22  |XRVADHXREK  |1312        |SXCMPZMQIHRAXAT|2015-03-01  |KAAQYGXUSW  |2013        |DLWVRDDLATBVYJM|2018-02-26  |XENKTNDRSF  |4741        |RSLEOZKUGQWWQHA|2021-12-05  |QIYAGXRRZV  |8981        |LQYAEUYOAEDAQCP|2018-05-18  |XFLNBRMWAW  |5777        |ZMJKTKUBQBNTYAW|2017-03-24  |IEUUXOUEDN  |7885        |\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nyc.taxis_100M_50COLUMNS LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc1fd11-9b00-41ff-85bb-91485955a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|extra_col_0|extra_col_1|extra_col_2    |extra_col_3|extra_col_4|extra_col_5|extra_col_6    |extra_col_7|extra_col_8|extra_col_9|extra_col_10   |extra_col_11|extra_col_12|extra_col_13|extra_col_14   |extra_col_15|extra_col_16|extra_col_17|extra_col_18   |extra_col_19|extra_col_20|extra_col_21|extra_col_22   |extra_col_23|extra_col_24|extra_col_25|extra_col_26   |extra_col_27|extra_col_28|extra_col_29|extra_col_30   |extra_col_31|extra_col_32|extra_col_33|extra_col_34   |extra_col_35|extra_col_36|extra_col_37|extra_col_38   |extra_col_39|extra_col_40|extra_col_41|extra_col_42   |extra_col_43|extra_col_44|extra_col_45|extra_col_46   |extra_col_47|extra_col_48|extra_col_49|\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "|CRVJYYFPRY |3405       |VHHGQHQDNMLMIPS|2017-07-08 |EHZCMVTYTR |6011       |PZDNHBTEJHUIFER|2017-03-19 |MPTVSDKRWI |7538       |QSZXRCZQDMMERBV|2017-02-01  |NUWRTQHZVV  |8265        |HYQFXWKEJQGWIIO|2020-07-18  |BDQMDEAWWT  |6151        |FZLOSWRWFGPGJPY|2022-05-03  |JLDHZUWJZF  |7415        |VQPNVOEYZEHPAAO|2015-08-08  |KAKFZOAYII  |1381        |HBGHKXMXOYDDHTP|2020-08-22  |OVLPLOSMES  |5376        |QHMUTENGRMPYXJM|2019-05-15  |SZEVCAXDGQ  |3266        |NBREANDKYAJEQIL|2020-04-12  |ZYBZQERESV  |8834        |OANCJRHRNWTIZCP|2016-10-20  |TUZMJVVYHP  |4471        |XEXDVCTDMUJNSKU|2023-01-23  |TTJFJKQBFA  |8014        |MLZIXNJYRIVRWAI|2019-02-04  |QEABXWFKMP  |2650        |\n",
      "|ZEVLBWPGQJ |6080       |SUOPKZFESSIWDIK|2024-11-04 |EOEXFTCYQY |1005       |SFLWNPFPESYQWMS|2015-03-16 |TQBNMXCXBG |7449       |WHPUWPNIHFDDZWL|2016-05-21  |OZOHEUGTJJ  |156         |DLIVXKMLTUVTNVB|2017-07-20  |TWZJUTWMCT  |1198        |ARDJCYAOBGABCPQ|2019-06-13  |RFNIRMFACI  |4400        |QMHNATZVXWENFEI|2024-10-19  |YGRMLPRUVU  |7722        |LBJTHRNQUAUXERA|2016-04-05  |OGOQUILPBV  |3728        |YGYPJOMHKCLXCJU|2023-08-19  |MAQBDKWESA  |4934        |RJYNEDEPGGMFNIQ|2019-04-06  |SMADYJNTCL  |9976        |CSXDQLXHSISZZBG|2020-01-13  |ZWPGPLRLLD  |7943        |CZMLTVPUYYFEQNZ|2024-01-05  |UCDGFSACQY  |4087        |YBGGQELRIQJYBCG|2024-06-14  |JSYEADUWSP  |298         |\n",
      "|ESTOMZIZJS |7655       |XTMQERCZSOJXIEQ|2020-02-26 |PSGSMRGEFC |185        |IKSWPIPJTFRCAPM|2022-01-29 |PIRPFLNTSV |5045       |CSKIFKPNFVMPFAO|2021-03-20  |XVAVGZDMKO  |8084        |CCAKAQWSCTLGUCY|2017-03-03  |BOAZBTOCUF  |6811        |LYHIKSZPZCBRNSJ|2016-07-13  |RVBCOZAMDE  |8822        |PXSKFCLZZQRRTKW|2016-10-05  |FLUCNFNMFE  |2266        |VOWZICJEVPDKMWO|2017-12-06  |USCBGILZUI  |5251        |WLOKHDJWXSZSITE|2015-07-05  |BBGZRONGRG  |8938        |HKTKAXXJIBTCBUE|2017-05-13  |RXTIBGTUNY  |6989        |UNYUUQPBTYEYKMV|2020-01-14  |JVOPTTYSYG  |6315        |CMCDAVDVYBBOMDN|2022-07-17  |DGCGFFSJIS  |4781        |SPXFPARBAZTHRDH|2019-10-07  |QKXERJXMAU  |1327        |\n",
      "|MNEFJUDFRU |2319       |UABZVIIKRDPBEVB|2016-01-08 |JFUPERNUAD |817        |NGPPXDHEIDNZYEP|2023-07-25 |KSRLXACVJP |772        |MRMSLMPOQDSIREV|2017-05-28  |SPIGXYAMKO  |5005        |NWBCYYFPVKRDRYU|2019-07-24  |HSSVEINPMN  |4513        |VXGXXQHCUXZMRUI|2016-09-22  |NXLMRFXRVJ  |2489        |BGHMBRUEHQVNTPE|2021-07-08  |INHDTTUATX  |1271        |EORXHVEAEPWNFJH|2018-12-21  |HSIYBSXWRW  |1519        |FDTAFBHYHOVCLFQ|2020-02-03  |AOWWWMDZEV  |5531        |ATEVUXMXPRZEOVE|2022-05-10  |PHALBHWQZD  |8957        |KCZYBAVQDYAHEKZ|2024-11-12  |YZLBICSNBH  |1813        |HCGNFIGJTDRHTUU|2022-02-16  |XMPTHRPGPA  |9616        |XAIFPRUHIZFHREA|2017-12-31  |YEPNWISIUC  |290         |\n",
      "|QZICPJYGYS |3172       |FPVZIQDURFYAICG|2020-02-27 |LAGCOCZDZU |8085       |HCUWSFXFQEWTJYT|2018-11-04 |QBWHBOIZDO |6572       |JFHHLULQOYJGMIU|2019-04-29  |AIIUFEQUEO  |5838        |LBZCFDANBFLWNDB|2019-10-25  |XDNVCSJTDS  |9865        |YMOIJBPFAYOPUYV|2019-08-31  |NIRBVUZUQM  |6312        |QWENGXAZEFBBACL|2024-06-06  |CTGOHEJXZF  |3457        |VSBJZIYPROBEWIQ|2020-06-26  |PKMSUTCONU  |212         |VFXKMFQXWOVOGQS|2018-07-12  |FQUNKMRBVA  |905         |HMQNZPGRTGHGXCK|2016-09-30  |BDLXUVNNLJ  |8503        |BPYOHSTVOMNBQWC|2016-05-15  |WLJYUCDGIM  |8852        |ANSVCKXHNNGGSSJ|2016-03-07  |LMKCPGIIHE  |9367        |HRPWFVKLDAWWZBN|2018-09-18  |DQQAYCSOKN  |8600        |\n",
      "|SEATAXWGIO |1762       |HNMMWGBNTWTNKRA|2023-07-31 |XIRJAIOAGJ |6748       |WRBEBOGRSNZFNJL|2020-12-10 |ZFRZGXUZZX |8322       |DAOGZISJPCXNSKV|2018-02-26  |MKKGLUXUJC  |3882        |CGYYIMXXEWEIFKN|2019-03-11  |GVPQYWZGTR  |9203        |BZROEMGIPGBCULU|2015-09-19  |NSNJKTCQSH  |8950        |DBTWMXPVLXYGVEZ|2020-09-20  |UXBJIXFULV  |8805        |WDGAGNBYNGKOCDX|2022-12-26  |KPRFZBHBQS  |3396        |ORIBSCCFSHCAICW|2016-05-21  |LAUHNGPNWY  |8719        |PHVIUTIWQEPIQWQ|2023-10-17  |UZQMOAQTZO  |4728        |MOIPFSBXOOXBUEW|2020-10-13  |ZBZBJVYZQK  |135         |KHLWROGDACAPYQB|2019-05-27  |STCLPYXYMQ  |7427        |RXRUEEBUNRFIGZR|2023-04-29  |TUGKKSLEWY  |7473        |\n",
      "|FDQKGJNHQV |8611       |AODVESKGNLHNBII|2016-12-09 |RETPGRVXGA |7994       |DPCEHFUHPCOZRXA|2023-03-04 |GLMGEZZQSQ |3614       |YLCBYGMRAYLKXPI|2019-03-06  |UVBJFWHQIO  |5241        |BNAPFATSKQFCZKG|2025-02-19  |GOQLRKBIFI  |7388        |GBXVNUKEDOQWJXX|2024-10-10  |YCPKSGOCBR  |4584        |IEMECLIZLLAGONB|2015-08-19  |QXOHYPCJWP  |6027        |OPBDPKJXCRMKAHQ|2019-05-29  |PAZYCHQXEX  |1211        |KJMUGOXASXNLDYL|2023-09-24  |BATYVQTGSX  |6250        |VKACEMAVWEVRCXZ|2023-01-21  |PDRFWXHSWD  |8260        |UAGBNDPWJFPKITG|2024-07-23  |DLSMKPLEHS  |5960        |DKWZNLYUFYHHBBI|2020-09-08  |GDMHOSTFEC  |8409        |YFJDUQGBIWVTZZU|2023-02-05  |GXCFDICRJI  |9023        |\n",
      "|SHYLFLCXUN |8691       |PVLUCIJDGGIPZLH|2017-07-30 |GUYGMFXXYP |7327       |LQSBBIOVZHJTRIN|2024-11-22 |GMDNJYPOMJ |4050       |GEUNUOCBUWHQANT|2023-09-29  |NQCZUFPHWU  |815         |UVETRMLFAHPWYDS|2021-11-20  |PEYCTFQNTC  |9721        |BFDEYOIYUUOWRWW|2017-06-19  |PRKUVPMQGU  |7763        |QCVDTSYQNYLPVHO|2017-05-26  |FGZHPXEPDK  |842         |HEFFDQNFKBENAML|2020-07-07  |CXZMGKEVUK  |9926        |OZKZKMFWMFTMTWC|2020-09-12  |FHGKEZDGXQ  |4744        |HADFVZSCYJUISJM|2021-03-10  |YIMYULDZKX  |812         |EYJERBUZFOUMRMY|2015-08-27  |RMSEHMNKXK  |6121        |MKNSZABMOLBCQYO|2022-01-22  |RZRICVJABR  |5231        |GRGHBKZUJQKOKEO|2017-12-23  |ZQXNBNGYKG  |3712        |\n",
      "|JMSZWNEWYO |7634       |HDSCITKVZBZUASD|2024-12-25 |LWZKBTYPBK |7654       |OKURSCZLNSTOJAT|2024-10-07 |VBRCEIQTEW |3938       |KTQMVTLDLTVZRSA|2019-12-25  |JOSLHMXESN  |5561        |XUALXESBZMRIGFR|2019-08-22  |RQEJQGUXFN  |4859        |JMCQBJIOIIBUJRT|2022-10-21  |YOLQVZNCON  |1381        |CSESTEMFHTQTZUV|2018-05-29  |MHTXSJUIDX  |5371        |KVBOVFOUNMKBYOB|2018-08-21  |ZZJXQIOYJK  |2472        |HIEAPRZZMAULJXE|2024-01-23  |GFHKCOOILT  |7840        |FDGXEBUUVQCLLQD|2023-08-23  |CWELYAZEMP  |4155        |EUCCOMRDTDUDMPN|2024-04-17  |TFUYCRCWLP  |7130        |XDEOOGYURWSOSDS|2021-04-28  |GASSQLSKKY  |3080        |MAEHYLKOEFJTQSN|2020-02-07  |GHBQZAHGEZ  |7908        |\n",
      "|MHDNKBFBPZ |4004       |VZBUSMZSYNGWYXN|2018-04-24 |RPGFRHYFGA |6193       |HGIWGYUGJBVOWWB|2017-03-15 |ZMJZHLDSAP |7491       |LRTFLCEJQMCYJLE|2022-03-29  |LASUBDATIG  |8038        |GDRYHVCZNROJVWK|2023-03-13  |MSXIIFWYNK  |1088        |FENDBZFAXAACEKF|2022-01-28  |AUNUYCQQUV  |4069        |SJDJSFLVNBMKCBC|2018-01-08  |NKZKSFGBHF  |842         |GRJGTUKNFAHWXYQ|2020-11-23  |WGCNYAHMOY  |3553        |ZRIWAGPZQQLPWTD|2016-03-18  |UNOOMJQOFL  |9623        |LUNKGTRLJKBWLPN|2021-02-16  |LMQWBZQUMF  |8195        |RSPPSLRSYJBNVWW|2015-08-31  |KIHKWXWFVW  |4662        |XKZTDGYXEOEALRN|2022-01-04  |JFKTNRATQF  |1385        |CKTXGUJMUFNLBVN|2021-06-11  |GEGVTNSPMS  |5136        |\n",
      "+-----------+-----------+---------------+-----------+-----------+-----------+---------------+-----------+-----------+-----------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+---------------+------------+------------+------------+\n",
      "\n",
      "Time taken for the operation: 0.5980069637298584 seconds\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# # Start time\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Run the Spark SQL query\n",
    "# spark.sql(\"SELECT * FROM nyc.taxis_100M_50COLUMNS LIMIT 10\").show(truncate=False)\n",
    "\n",
    "# # End time\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Calculate the duration\n",
    "# execution_time = end_time - start_time\n",
    "\n",
    "# # Print the time taken\n",
    "# print(f\"Time taken for the operation: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c898ebca-b6c5-40d5-8ba8-90070d6dc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|start_date|end_date  |\n",
      "+----------+----------+\n",
      "|2015-03-09|2025-02-22|\n",
      "+----------+----------+\n",
      "\n",
      "Time taken for the operation: 1.1512253284454346 seconds\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# # Start time\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Query to get the first (start) and last (end) dates\n",
    "# query = \"\"\"\n",
    "# SELECT MIN(extra_col_3) AS start_date, MAX(extra_col_3) AS end_date\n",
    "# FROM nyc.taxis_1000_50COLUMNS\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute the query\n",
    "# result = spark.sql(query)\n",
    "\n",
    "# # Show the result\n",
    "# result.show(truncate=False)\n",
    "\n",
    "# # End time\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Calculate the duration\n",
    "# execution_time = end_time - start_time\n",
    "\n",
    "# # Print the time taken\n",
    "# print(f\"Time taken for the operation: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1495a719-90c9-4c30-8baa-99b781a4602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|total_records|\n",
      "+-------------+\n",
      "|         1010|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"SELECT COUNT(*) AS total_records FROM demo.nyc.taxis_1000_50COLUMNS;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8481d7b8-5c97-4f30-a7b8-a47a9355a9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|col_name    |data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|extra_col_0 |string   |NULL   |\n",
      "|extra_col_1 |int      |NULL   |\n",
      "|extra_col_2 |string   |NULL   |\n",
      "|extra_col_3 |date     |NULL   |\n",
      "|extra_col_4 |string   |NULL   |\n",
      "|extra_col_5 |int      |NULL   |\n",
      "|extra_col_6 |string   |NULL   |\n",
      "|extra_col_7 |date     |NULL   |\n",
      "|extra_col_8 |string   |NULL   |\n",
      "|extra_col_9 |int      |NULL   |\n",
      "|extra_col_10|string   |NULL   |\n",
      "|extra_col_11|date     |NULL   |\n",
      "|extra_col_12|string   |NULL   |\n",
      "|extra_col_13|int      |NULL   |\n",
      "|extra_col_14|string   |NULL   |\n",
      "|extra_col_15|date     |NULL   |\n",
      "|extra_col_16|string   |NULL   |\n",
      "|extra_col_17|int      |NULL   |\n",
      "|extra_col_18|string   |NULL   |\n",
      "|extra_col_19|date     |NULL   |\n",
      "+------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Spark SQL to describe the table and see its columns\n",
    "spark.sql(\"DESCRIBE nyc.taxis_100M_50COLUMNS\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f373cde-a1e6-489a-8f16-e405ba9261f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before update: 100000000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter percentage of records to update:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 1000000 records.\n"
     ]
    },
    {
     "ename": "ParseException",
     "evalue": "\n[PARSE_SYNTAX_ERROR] Syntax error at or near '<'.(line 1, pos 1406)\n\n== SQL ==\nUPDATE demo.nyc.taxis_100M_50COLUMNS SET extra_col_0 = 'Random_778', extra_col_1 = '6848', extra_col_2 = 'Random_594', extra_col_3 = '2024-06-05', extra_col_4 = 'Random_622', extra_col_5 = '1083', extra_col_6 = 'Random_628', extra_col_7 = '2024-10-13', extra_col_8 = 'Random_449', extra_col_9 = '937', extra_col_10 = 'Random_584', extra_col_11 = '2024-03-12', extra_col_12 = 'Random_345', extra_col_13 = '2415', extra_col_14 = 'Random_380', extra_col_15 = '2024-07-11', extra_col_16 = 'Random_104', extra_col_17 = '3383', extra_col_18 = 'Random_842', extra_col_19 = '2024-12-09', extra_col_20 = 'Random_576', extra_col_21 = '4270', extra_col_22 = 'Random_932', extra_col_23 = '2024-04-11', extra_col_24 = 'Random_169', extra_col_25 = '2223', extra_col_26 = 'Random_540', extra_col_27 = '2024-12-18', extra_col_28 = 'Random_851', extra_col_29 = '5201', extra_col_30 = 'Random_827', extra_col_31 = '2024-09-15', extra_col_32 = 'Random_144', extra_col_33 = '666', extra_col_34 = 'Random_127', extra_col_35 = '2024-11-22', extra_col_36 = 'Random_479', extra_col_37 = '3089', extra_col_38 = 'Random_146', extra_col_39 = '2024-12-18', extra_col_40 = 'Random_694', extra_col_41 = '8991', extra_col_42 = 'Random_331', extra_col_43 = '2024-12-09', extra_col_44 = 'Random_250', extra_col_45 = '2329', extra_col_46 = 'Random_278', extra_col_47 = '2025-02-03', extra_col_48 = 'Random_277', extra_col_49 = '4037' WHERE <primary_key_column> = 13613686\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Step 7: Execute the update queries\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m update_queries:\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Step 8: Get total records after update (if needed, to verify)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# total_records_after = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Step 9: Print final output\u001b[39;00m\n\u001b[1;32m     53\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \n[PARSE_SYNTAX_ERROR] Syntax error at or near '<'.(line 1, pos 1406)\n\n== SQL ==\nUPDATE demo.nyc.taxis_100M_50COLUMNS SET extra_col_0 = 'Random_778', extra_col_1 = '6848', extra_col_2 = 'Random_594', extra_col_3 = '2024-06-05', extra_col_4 = 'Random_622', extra_col_5 = '1083', extra_col_6 = 'Random_628', extra_col_7 = '2024-10-13', extra_col_8 = 'Random_449', extra_col_9 = '937', extra_col_10 = 'Random_584', extra_col_11 = '2024-03-12', extra_col_12 = 'Random_345', extra_col_13 = '2415', extra_col_14 = 'Random_380', extra_col_15 = '2024-07-11', extra_col_16 = 'Random_104', extra_col_17 = '3383', extra_col_18 = 'Random_842', extra_col_19 = '2024-12-09', extra_col_20 = 'Random_576', extra_col_21 = '4270', extra_col_22 = 'Random_932', extra_col_23 = '2024-04-11', extra_col_24 = 'Random_169', extra_col_25 = '2223', extra_col_26 = 'Random_540', extra_col_27 = '2024-12-18', extra_col_28 = 'Random_851', extra_col_29 = '5201', extra_col_30 = 'Random_827', extra_col_31 = '2024-09-15', extra_col_32 = 'Random_144', extra_col_33 = '666', extra_col_34 = 'Random_127', extra_col_35 = '2024-11-22', extra_col_36 = 'Random_479', extra_col_37 = '3089', extra_col_38 = 'Random_146', extra_col_39 = '2024-12-18', extra_col_40 = 'Random_694', extra_col_41 = '8991', extra_col_42 = 'Random_331', extra_col_43 = '2024-12-09', extra_col_44 = 'Random_250', extra_col_45 = '2329', extra_col_46 = 'Random_278', extra_col_47 = '2025-02-03', extra_col_48 = 'Random_277', extra_col_49 = '4037' WHERE <primary_key_column> = 13613686\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------^^^\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Define table name\n",
    "table_name = \"demo.nyc.taxis_100M_50COLUMNS\"  # Change this to your actual table\n",
    "\n",
    "# Step 1: Get total records before update\n",
    "start_time = time.time()\n",
    "total_records_before = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "print(f\"Total records before update: {total_records_before}\")\n",
    "\n",
    "# Step 2: Ask user input for update percentage\n",
    "update_percentage = float(input(\"Enter percentage of records to update: \"))\n",
    "\n",
    "# Step 3: Calculate records to update\n",
    "num_records_to_update = max(1, int((update_percentage / 100) * total_records_before))\n",
    "print(f\"Updating {num_records_to_update} records.\")\n",
    "\n",
    "# Step 4: Get table schema (cached once)\n",
    "schema_df = spark.sql(f\"DESCRIBE {table_name}\").collect()\n",
    "schema_dict = {row[\"col_name\"]: row[\"data_type\"] for row in schema_df if not row[\"col_name\"].startswith(\"#\")}\n",
    "columns = list(schema_dict.keys())\n",
    "\n",
    "# Step 5: Function to generate random values with correct data types for update\n",
    "def generate_random_value(data_type):\n",
    "    if \"int\" in data_type:\n",
    "        return random.randint(1, 10000)  # INT values\n",
    "    elif \"string\" in data_type:\n",
    "        return f\"Random_{random.randint(100, 999)}\"  # STRING values\n",
    "    elif \"date\" in data_type:\n",
    "        return (datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d')  # DATE values\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "# Step 6: Update existing records in bulk\n",
    "update_queries = []\n",
    "for _ in range(num_records_to_update):\n",
    "    # Pick a random record to update (you can add specific conditions if needed)\n",
    "    random_id = random.randint(1, total_records_before)  # Assuming there's a primary key to target\n",
    "    update_clause = \", \".join([f\"{col_name} = '{generate_random_value(schema_dict[col_name])}'\" for col_name in columns])\n",
    "    update_queries.append(f\"UPDATE {table_name} SET {update_clause} WHERE <primary_key_column> = {random_id}\")  # Replace <primary_key_column> with actual primary key column\n",
    "\n",
    "# Step 7: Execute the update queries\n",
    "for query in update_queries:\n",
    "    spark.sql(query)\n",
    "\n",
    "# Step 8: Get total records after update (if needed, to verify)\n",
    "# total_records_after = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "\n",
    "# Step 9: Print final output\n",
    "end_time = time.time()\n",
    "# print(f\"Total records after update: {total_records_after}\")\n",
    "print(f\"✅ Successfully updated {num_records_to_update} records!\")\n",
    "print(f\"⏳ Total time taken for update: {round(end_time - start_time, 2)} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8d8b7d5-9a7e-48dd-bef9-2f4813bbda16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before update: 10000000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter percentage of records to update:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 100000 records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/26 12:09:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/26 12:09:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/26 12:09:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/26 12:09:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/26 12:09:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/26 12:09:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/26 12:09:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/26 12:09:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "ERROR:root:KeyboardInterrupt while sending command.                             \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/local/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Apply the update using `withColumn`\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m         update_df \u001b[38;5;241m=\u001b[39m update_df\u001b[38;5;241m.\u001b[39mwithColumn(\n\u001b[1;32m     55\u001b[0m             col_name,\n\u001b[0;32m---> 56\u001b[0m             F\u001b[38;5;241m.\u001b[39mwhen(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mextra_col_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_ids\u001b[49m\u001b[43m)\u001b[49m, F\u001b[38;5;241m.\u001b[39mlit(random_value))\u001b[38;5;241m.\u001b[39motherwise(F\u001b[38;5;241m.\u001b[39mcol(col_name))\n\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Step 5: Write back the updated DataFrame\u001b[39;00m\n\u001b[1;32m     60\u001b[0m update_df\u001b[38;5;241m.\u001b[39mwriteTo(table_name)\u001b[38;5;241m.\u001b[39moverwritePartitions()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/column.py:972\u001b[0m, in \u001b[0;36mColumn.isin\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cols[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m    969\u001b[0m     cols \u001b[38;5;241m=\u001b[39m cast(Tuple, cols[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    970\u001b[0m cols \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    971\u001b[0m     Tuple,\n\u001b[0;32m--> 972\u001b[0m     [c\u001b[38;5;241m.\u001b[39m_jc \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01melse\u001b[39;00m _create_column_from_literal(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols],\n\u001b[1;32m    973\u001b[0m )\n\u001b[1;32m    974\u001b[0m sc \u001b[38;5;241m=\u001b[39m get_active_spark_context()\n\u001b[1;32m    975\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misin\u001b[39m\u001b[38;5;124m\"\u001b[39m)(_to_seq(sc, cols))\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/column.py:972\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cols[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m    969\u001b[0m     cols \u001b[38;5;241m=\u001b[39m cast(Tuple, cols[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    970\u001b[0m cols \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    971\u001b[0m     Tuple,\n\u001b[0;32m--> 972\u001b[0m     [c\u001b[38;5;241m.\u001b[39m_jc \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_create_column_from_literal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols],\n\u001b[1;32m    973\u001b[0m )\n\u001b[1;32m    974\u001b[0m sc \u001b[38;5;241m=\u001b[39m get_active_spark_context()\n\u001b[1;32m    975\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misin\u001b[39m\u001b[38;5;124m\"\u001b[39m)(_to_seq(sc, cols))\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/column.py:51\u001b[0m, in \u001b[0;36m_create_column_from_literal\u001b[0;34m(literal)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_column_from_literal\u001b[39m(literal: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiteralType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecimalLiteral\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     50\u001b[0m     sc \u001b[38;5;241m=\u001b[39m get_active_spark_context()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJVMView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlit\u001b[49m(literal)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1535\u001b[0m, in \u001b[0;36mJavaClass.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mREFLECTION_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1531\u001b[0m     proto\u001b[38;5;241m.\u001b[39mREFL_GET_MEMBER_SUB_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fqn \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1533\u001b[0m     name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1534\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1535\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(answer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m answer[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mSUCCESS:\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mMETHOD_TYPE:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Define table name\n",
    "table_name = \"demo.nyc.taxis_100M_50COLUMNS\"  # Change this to your actual table\n",
    "\n",
    "# Step 1: Get total records before update\n",
    "start_time = time.time()\n",
    "total_records_before = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "print(f\"Total records before update: {total_records_before}\")\n",
    "\n",
    "# Step 2: Ask user input for update percentage\n",
    "update_percentage = float(input(\"Enter percentage of records to update: \"))\n",
    "\n",
    "# Step 3: Calculate records to update\n",
    "num_records_to_update = max(1, int((update_percentage / 100) * total_records_before))\n",
    "print(f\"Updating {num_records_to_update} records.\")\n",
    "\n",
    "# Step 4: Get table schema (cached once)\n",
    "schema_df = spark.sql(f\"DESCRIBE {table_name}\").collect()\n",
    "schema_dict = {row[\"col_name\"]: row[\"data_type\"] for row in schema_df if not row[\"col_name\"].startswith(\"#\")}\n",
    "columns = list(schema_dict.keys())\n",
    "\n",
    "# Step 5: Function to generate random values with correct data types for update\n",
    "def generate_random_value(data_type):\n",
    "    if \"int\" in data_type.lower():\n",
    "        return random.randint(1, 10000)  # INT values\n",
    "    elif \"string\" in data_type.lower():\n",
    "        return f\"Random_{random.randint(100, 999)}\"  # STRING values\n",
    "    elif \"date\" in data_type.lower():\n",
    "        return (datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d')  # DATE values\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "# Step 6: Generate random updates without using WHERE clause or JOIN\n",
    "update_queries = []\n",
    "for _ in range(num_records_to_update):\n",
    "    update_clause = \", \".join([f\"{col_name} = '{generate_random_value(schema_dict[col_name])}'\" for col_name in columns])\n",
    "    update_queries.append(f\"UPDATE {table_name} SET {update_clause}\")  # No WHERE clause used\n",
    "\n",
    "# Step 7: Execute the update queries\n",
    "for query in update_queries:\n",
    "    spark.sql(query)\n",
    "\n",
    "# Step 8: Get total records after update (if needed, to verify)\n",
    "# total_records_after = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "\n",
    "# Step 9: Print final output\n",
    "end_time = time.time()\n",
    "# print(f\"Total records after update: {total_records_after}\")\n",
    "print(f\"✅ Successfully updated {num_records_to_update} records!\")\n",
    "print(f\"⏳ Total time taken for update: {round(end_time - start_time, 2)} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae1d660f-aba3-4dbc-b673-85e1ac640710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before insert: 1040\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter percentage of records to insert:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 10 new records.\n",
      "✅ Successfully inserted 10 new records!\n",
      "⏳ Total time taken: 2.86 seconds.\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# import random\n",
    "# from datetime import datetime, timedelta\n",
    "# import time\n",
    "\n",
    "# # Define table name\n",
    "# table_name = \"demo.nyc.taxis_1000_50COLUMNS\"  # Change this to your actual table\n",
    "\n",
    "# # Step 1: Get total records before insert\n",
    "# start_time = time.time()\n",
    "# total_records_before = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "# print(f\"Total records before insert: {total_records_before}\")\n",
    "\n",
    "# # Step 2: Ask user input for insert percentage\n",
    "# insert_percentage = float(input(\"Enter percentage of records to insert: \"))\n",
    "\n",
    "# # Step 3: Calculate records to insert\n",
    "# num_records = max(1, int((insert_percentage / 100) * total_records_before))\n",
    "# print(f\"Inserting {num_records} new records.\")\n",
    "\n",
    "# # Step 4: Get table schema (cached once)\n",
    "# schema_df = spark.sql(f\"DESCRIBE {table_name}\").collect()\n",
    "# schema_dict = {row[\"col_name\"]: row[\"data_type\"] for row in schema_df if not row[\"col_name\"].startswith(\"#\")}\n",
    "# columns = list(schema_dict.keys())\n",
    "\n",
    "# # Step 5: Function to generate random values with correct data types\n",
    "# def generate_random_value(data_type):\n",
    "#     if \"int\" in data_type:\n",
    "#         return str(random.randint(1, 10000))  # INT values\n",
    "#     elif \"string\" in data_type:\n",
    "#         return f\"'Random_{random.randint(100, 999)}'\"  # STRING values\n",
    "#     elif \"date\" in data_type:\n",
    "#         return f\"CAST('{(datetime.today() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d')}' AS DATE)\"  # DATE values\n",
    "#     else:\n",
    "#         return \"NULL\"\n",
    "\n",
    "# # Step 6: Insert new records in bulk\n",
    "# insert_values = []\n",
    "# for _ in range(num_records):\n",
    "#     values = [generate_random_value(schema_dict[col_name]) for col_name in columns]\n",
    "#     insert_values.append(f\"({', '.join(values)})\")\n",
    "\n",
    "# insert_query = f\"INSERT INTO {table_name} VALUES {', '.join(insert_values)}\"\n",
    "# spark.sql(insert_query)\n",
    "\n",
    "# # Step 7: Get total records after insert\n",
    "# #total_records_after = spark.sql(f\"SELECT COUNT(*) FROM {table_name}\").collect()[0][0]\n",
    "\n",
    "# # Step 8: Print final output\n",
    "# end_time = time.time()\n",
    "# #print(f\"Total records after insert: {total_records_after}\")\n",
    "# print(f\"✅ Successfully inserted {num_records} new records!\")\n",
    "# print(f\"⏳ Total time taken: {round(end_time - start_time, 2)} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e63d77-8418-446f-8562-7a1e1a0e982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|total_records|\n",
      "+-------------+\n",
      "|         1050|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS total_records FROM demo.nyc.taxis_1000_50COLUMNS;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd64b5b-49c2-4de9-8c3e-3c11164f42ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
